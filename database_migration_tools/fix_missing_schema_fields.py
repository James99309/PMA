#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤äº‘ç«¯æ•°æ®åº“ç¼ºå¤±çš„å…³é”®å­—æ®µ
ä¸»è¦è§£å†³éadminç”¨æˆ·500é”™è¯¯é—®é¢˜
"""

import psycopg2
import logging
import datetime
import subprocess
import os
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('ä¿®å¤ç¼ºå¤±å­—æ®µ')

class MissingFieldsFixer:
    def __init__(self):
        self.timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        self.backup_dir = '/Users/nijie/Documents/PMA/cloud_db_backups'
        
        self.local_db_url = "postgresql://nijie@localhost:5432/pma_local"
        self.cloud_db_url = "postgresql://pma_db_ovs_user:oUKdxwqXDvCrgkg3fkZ33axXgDF21D51@dpg-d170laodl3ps739trgp0-a.singapore-postgres.render.com/pma_db_ovs"
    
    def parse_db_url(self, db_url):
        parsed = urlparse(db_url)
        return {
            'host': parsed.hostname,
            'port': parsed.port or 5432,
            'user': parsed.username,
            'password': parsed.password,
            'dbname': parsed.path.lstrip('/')
        }
    
    def backup_cloud_database(self):
        """å¤‡ä»½äº‘ç«¯æ•°æ®åº“"""
        logger.info("ğŸ” [1/4] å¤‡ä»½äº‘ç«¯æ•°æ®åº“...")
        
        cloud_params = self.parse_db_url(self.cloud_db_url)
        backup_file = f"{self.backup_dir}/pma_db_ovs_backup_before_field_fix_{self.timestamp}.sql"
        
        try:
            cmd = [
                'pg_dump',
                '-h', cloud_params['host'],
                '-p', str(cloud_params['port']),
                '-U', cloud_params['user'],
                '-d', cloud_params['dbname'],
                '--verbose',
                '--clean',
                '--if-exists',
                '--no-owner',
                '--no-privileges',
                '-f', backup_file
            ]
            
            env = {**dict(os.environ), 'PGPASSWORD': cloud_params['password']}
            
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_file}")
                return backup_file
            else:
                logger.error(f"âŒ å¤‡ä»½å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            logger.error(f"å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return None
    
    def check_missing_fields(self):
        """æ£€æŸ¥äº‘ç«¯æ•°æ®åº“ç¼ºå¤±çš„å­—æ®µ"""
        logger.info("ğŸ” [2/4] æ£€æŸ¥ç¼ºå¤±å­—æ®µ...")
        
        # è¿æ¥æœ¬åœ°æ•°æ®åº“è·å–æ­£ç¡®çš„ç»“æ„
        local_params = self.parse_db_url(self.local_db_url)
        local_conn = psycopg2.connect(**local_params)
        local_cursor = local_conn.cursor()
        
        # è¿æ¥äº‘ç«¯æ•°æ®åº“
        cloud_params = self.parse_db_url(self.cloud_db_url)
        cloud_conn = psycopg2.connect(**cloud_params)
        cloud_cursor = cloud_conn.cursor()
        
        missing_fields = {}
        
        # æ£€æŸ¥usersè¡¨
        logger.info("ğŸ“‹ æ£€æŸ¥usersè¡¨...")
        local_cursor.execute("""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = 'users'
            ORDER BY ordinal_position
        """)
        local_users_columns = {row[0]: row for row in local_cursor.fetchall()}
        
        cloud_cursor.execute("""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = 'users'
            ORDER BY ordinal_position
        """)
        cloud_users_columns = {row[0]: row for row in cloud_cursor.fetchall()}
        
        users_missing = []
        for col_name, col_info in local_users_columns.items():
            if col_name not in cloud_users_columns:
                users_missing.append((col_name, col_info))
                logger.warning(f"âš ï¸ usersè¡¨ç¼ºå¤±å­—æ®µ: {col_name} ({col_info[1]})")
        
        if users_missing:
            missing_fields['users'] = users_missing
        
        # æ£€æŸ¥role_permissionsè¡¨
        logger.info("ğŸ“‹ æ£€æŸ¥role_permissionsè¡¨...")
        local_cursor.execute("""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = 'role_permissions'
            ORDER BY ordinal_position
        """)
        local_rp_columns = {row[0]: row for row in local_cursor.fetchall()}
        
        cloud_cursor.execute("""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = 'role_permissions'
            ORDER BY ordinal_position
        """)
        cloud_rp_columns = {row[0]: row for row in cloud_cursor.fetchall()}
        
        rp_missing = []
        for col_name, col_info in local_rp_columns.items():
            if col_name not in cloud_rp_columns:
                rp_missing.append((col_name, col_info))
                logger.warning(f"âš ï¸ role_permissionsè¡¨ç¼ºå¤±å­—æ®µ: {col_name} ({col_info[1]})")
        
        if rp_missing:
            missing_fields['role_permissions'] = rp_missing
        
        local_conn.close()
        cloud_conn.close()
        
        return missing_fields
    
    def add_missing_fields(self, missing_fields):
        """æ·»åŠ ç¼ºå¤±çš„å­—æ®µåˆ°äº‘ç«¯æ•°æ®åº“"""
        logger.info("ğŸ” [3/4] æ·»åŠ ç¼ºå¤±å­—æ®µ...")
        
        if not missing_fields:
            logger.info("âœ… æ²¡æœ‰ç¼ºå¤±å­—æ®µï¼Œæ— éœ€ä¿®å¤")
            return True
        
        cloud_params = self.parse_db_url(self.cloud_db_url)
        conn = psycopg2.connect(**cloud_params)
        conn.autocommit = False
        cursor = conn.cursor()
        
        operations = []
        
        try:
            for table_name, fields in missing_fields.items():
                logger.info(f"ğŸ”§ ä¿®å¤è¡¨: {table_name}")
                
                for col_name, col_info in fields:
                    col_name, data_type, is_nullable, col_default = col_info
                    
                    # æ„å»ºALTER TABLEè¯­å¥
                    sql = f"ALTER TABLE {table_name} ADD COLUMN {col_name} {data_type}"
                    
                    if col_default is not None:
                        sql += f" DEFAULT {col_default}"
                    
                    if is_nullable == 'NO':
                        # å¦‚æœå­—æ®µä¸å…è®¸NULLï¼Œå…ˆæ·»åŠ ä¸ºå…è®¸NULLï¼Œç„¶åå¯ä»¥åç»­è®¾ç½®é»˜è®¤å€¼
                        pass  # æš‚æ—¶å…è®¸NULLï¼Œé¿å…çº¦æŸå†²çª
                    
                    logger.info(f"ğŸ”„ æ‰§è¡Œ: {sql}")
                    cursor.execute(sql)
                    operations.append(f"æ·»åŠ å­—æ®µ {table_name}.{col_name}")
            
            # æäº¤æ›´æ”¹
            conn.commit()
            logger.info(f"âœ… å­—æ®µæ·»åŠ æˆåŠŸï¼Œæ‰§è¡Œäº† {len(operations)} ä¸ªæ“ä½œ")
            
            for op in operations:
                logger.info(f"   - {op}")
            
            cursor.close()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"âŒ å­—æ®µæ·»åŠ å¤±è´¥: {str(e)}")
            conn.rollback()
            cursor.close()
            conn.close()
            return False
    
    def generate_fix_report(self, missing_fields, backup_file, fix_success):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        logger.info("ğŸ” [4/4] ç”Ÿæˆä¿®å¤æŠ¥å‘Š...")
        
        report_file = f"{self.backup_dir}/missing_fields_fix_report_{self.timestamp}.md"
        
        report_content = f"""# ç¼ºå¤±å­—æ®µä¿®å¤æŠ¥å‘Š

## ä¿®å¤æ¦‚è¿°
- ä¿®å¤æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ç›®æ ‡æ•°æ®åº“: äº‘ç«¯PostgreSQL (pma_db_ovs)
- ä¿®å¤çŠ¶æ€: {'æˆåŠŸ' if fix_success else 'å¤±è´¥'}

## é—®é¢˜æè¿°
éadminç”¨æˆ·è®¿é—®é¡¹ç›®ç®¡ç†å’Œå®¢æˆ·ç®¡ç†æ—¶å‡ºç°500é”™è¯¯ï¼Œç»è¯Šæ–­å‘ç°äº‘ç«¯æ•°æ®åº“ç¼ºå¤±å…³é”®å­—æ®µï¼š

### ç¼ºå¤±å­—æ®µåˆ†æ
"""
        
        if missing_fields:
            for table_name, fields in missing_fields.items():
                report_content += f"\n#### {table_name}è¡¨\n"
                for col_name, col_info in fields:
                    col_name, data_type, is_nullable, col_default = col_info
                    nullable_str = "ä¸å¯ç©º" if is_nullable == 'NO' else "å¯ç©º"
                    default_str = f" é»˜è®¤å€¼: {col_default}" if col_default else ""
                    report_content += f"- **{col_name}**: {data_type} ({nullable_str}){default_str}\n"
        else:
            report_content += "\nâœ… æ²¡æœ‰å‘ç°ç¼ºå¤±å­—æ®µ\n"
        
        report_content += f"""

## ä¿®å¤ç»“æœ
- å¤‡ä»½æ–‡ä»¶: {backup_file or 'æ— '}
- ä¿®å¤çŠ¶æ€: {'âœ… æˆåŠŸ' if fix_success else 'âŒ å¤±è´¥'}

## æ‰§è¡Œæ­¥éª¤
1. âœ… å¤‡ä»½äº‘ç«¯æ•°æ®åº“
2. âœ… æ£€æŸ¥ç¼ºå¤±å­—æ®µ
3. {'âœ…' if fix_success else 'âŒ'} æ·»åŠ ç¼ºå¤±å­—æ®µ
4. âœ… ç”Ÿæˆä¿®å¤æŠ¥å‘Š

## å®‰å…¨ç¡®è®¤
- âœ… ä¿®å¤å‰å·²å¤‡ä»½äº‘ç«¯æ•°æ®åº“
- âœ… ä»…æ·»åŠ ç¼ºå¤±å­—æ®µï¼Œä¸ä¿®æ”¹ç°æœ‰æ•°æ®
- âœ… æ‰€æœ‰æ“ä½œå¯å›æ»š

## åç»­å»ºè®®
1. æµ‹è¯•éadminç”¨æˆ·ç™»å½•å’Œæƒé™è®¿é—®
2. å¦‚æœä»æœ‰é—®é¢˜ï¼Œæ£€æŸ¥åº”ç”¨ä»£ç ä¸­çš„æƒé™é€»è¾‘
3. è€ƒè™‘å®Œæ•´çš„schemaåŒæ­¥ä»¥ç¡®ä¿ç»“æ„ä¸€è‡´æ€§
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ğŸ“‹ ä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„ä¿®å¤æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹ä¿®å¤ç¼ºå¤±å­—æ®µ...")
        
        try:
            # 1. å¤‡ä»½äº‘ç«¯æ•°æ®åº“
            backup_file = self.backup_cloud_database()
            if not backup_file:
                logger.error("âŒ å¤‡ä»½å¤±è´¥ï¼Œä¸­æ­¢ä¿®å¤")
                return False
            
            # 2. æ£€æŸ¥ç¼ºå¤±å­—æ®µ
            missing_fields = self.check_missing_fields()
            
            # 3. æ·»åŠ ç¼ºå¤±å­—æ®µ
            fix_success = self.add_missing_fields(missing_fields)
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            report_file = self.generate_fix_report(missing_fields, backup_file, fix_success)
            
            if fix_success:
                logger.info("ğŸ‰ ç¼ºå¤±å­—æ®µä¿®å¤å®Œæˆ!")
                logger.info(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
                logger.info("\nğŸ’¡ å»ºè®®:")
                logger.info("1. æµ‹è¯•éadminç”¨æˆ·ç™»å½•")
                logger.info("2. æ£€æŸ¥é¡¹ç›®ç®¡ç†å’Œå®¢æˆ·ç®¡ç†åŠŸèƒ½")
                logger.info("3. å¦‚æœä»æœ‰é”™è¯¯ï¼Œæ£€æŸ¥åº”ç”¨æƒé™é€»è¾‘")
            else:
                logger.error("âŒ å­—æ®µä¿®å¤å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Š")
            
            return fix_success
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return False

if __name__ == "__main__":
    fixer = MissingFieldsFixer()
    success = fixer.run()
    if not success:
        exit(1)