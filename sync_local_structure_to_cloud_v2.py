#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæ­¥æœ¬åœ°æ•°æ®åº“ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ (æ”¹è¿›ç‰ˆæœ¬)
1. å¤‡ä»½äº‘ç«¯æ•°æ®åº“å†…å®¹
2. æ¸…ç†äº‘ç«¯æ•°æ®åº“ç»“æ„
3. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„
4. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ï¼ˆä¸åŒ…å«æ•°æ®ï¼‰
"""

import os
import sys
import psycopg2
import subprocess
import logging
from datetime import datetime
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
LOCAL_DB_URL = "postgresql://nijie@localhost:5432/pma_local"
CLOUD_DB_URL = "postgresql://pma_db_ovs_user:oUKdxwqXDvCrgkg3fkZ33axXgDF21D51@dpg-d170laodl3ps739trgp0-a.singapore-postgres.render.com/pma_db_ovs"

def parse_database_url(db_url):
    """è§£ææ•°æ®åº“URL"""
    parsed = urlparse(db_url)
    return {
        'host': parsed.hostname,
        'port': parsed.port or 5432,
        'username': parsed.username,
        'password': parsed.password,
        'database': parsed.path.lstrip('/')
    }

def test_database_connection(db_url, db_name):
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        version = cursor.fetchone()[0]
        cursor.close()
        conn.close()
        logger.info(f"âœ… {db_name}æ•°æ®åº“è¿æ¥æˆåŠŸ")
        logger.info(f"   ç‰ˆæœ¬: {version[:50]}...")
        return True
    except Exception as e:
        logger.error(f"âŒ {db_name}æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

def backup_cloud_database():
    """å¤‡ä»½äº‘ç«¯æ•°æ®åº“"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_filename = f"cloud_backup_pma_db_ovs_{timestamp}.sql"
    backup_path = os.path.join('backups', backup_filename)
    
    # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
    os.makedirs('backups', exist_ok=True)
    
    try:
        logger.info("ğŸ”„ å¼€å§‹å¤‡ä»½äº‘ç«¯æ•°æ®åº“...")
        
        cloud_config = parse_database_url(CLOUD_DB_URL)
        
        # æ„å»ºpg_dumpå‘½ä»¤
        cmd = [
            'pg_dump',
            '--host', cloud_config['host'],
            '--port', str(cloud_config['port']),
            '--username', cloud_config['username'],
            '--no-password',
            '--format', 'plain',
            '--clean',
            '--create',
            '--encoding', 'UTF8',
            '--verbose',
            cloud_config['database']
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['PGPASSWORD'] = cloud_config['password']
        
        # æ‰§è¡Œå¤‡ä»½å‘½ä»¤
        with open(backup_path, 'w') as f:
            result = subprocess.run(
                cmd,
                stdout=f,
                stderr=subprocess.PIPE,
                env=env,
                text=True
            )
        
        if result.returncode == 0:
            file_size = os.path.getsize(backup_path) / (1024 * 1024)  # MB
            logger.info(f"âœ… äº‘ç«¯æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_filename}")
            logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            logger.info(f"   å¤‡ä»½è·¯å¾„: {backup_path}")
            return backup_path
        else:
            logger.error(f"âŒ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å¤±è´¥: {result.stderr}")
            if os.path.exists(backup_path):
                os.remove(backup_path)
            return None
            
    except Exception as e:
        logger.error(f"âŒ å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if os.path.exists(backup_path):
            os.remove(backup_path)
        return None

def clean_cloud_database():
    """æ¸…ç†äº‘ç«¯æ•°æ®åº“ç»“æ„"""
    try:
        logger.info("ğŸ”„ æ¸…ç†äº‘ç«¯æ•°æ®åº“ç»“æ„...")
        
        conn = psycopg2.connect(CLOUD_DB_URL)
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰è¡¨å
        cursor.execute("""
            SELECT tablename FROM pg_tables 
            WHERE schemaname = 'public'
        """)
        tables = [row[0] for row in cursor.fetchall()]
        
        # è·å–æ‰€æœ‰åºåˆ—å
        cursor.execute("""
            SELECT sequencename FROM pg_sequences 
            WHERE schemaname = 'public'
        """)
        sequences = [row[0] for row in cursor.fetchall()]
        
        # è·å–æ‰€æœ‰è§†å›¾å
        cursor.execute("""
            SELECT viewname FROM pg_views 
            WHERE schemaname = 'public'
        """)
        views = [row[0] for row in cursor.fetchall()]
        
        # åˆ é™¤æ‰€æœ‰å¤–é”®çº¦æŸ
        cursor.execute("""
            SELECT conname, conrelid::regclass 
            FROM pg_constraint 
            WHERE contype = 'f' AND connamespace = 'public'::regnamespace
        """)
        foreign_keys = cursor.fetchall()
        
        for fk_name, table_name in foreign_keys:
            try:
                cursor.execute(f'ALTER TABLE {table_name} DROP CONSTRAINT IF EXISTS "{fk_name}" CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤å¤–é”®çº¦æŸ {fk_name} å¤±è´¥: {e}")
        
        # åˆ é™¤æ‰€æœ‰è§†å›¾
        for view in views:
            try:
                cursor.execute(f'DROP VIEW IF EXISTS "{view}" CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤è§†å›¾ {view} å¤±è´¥: {e}")
        
        # åˆ é™¤æ‰€æœ‰è¡¨
        for table in tables:
            try:
                cursor.execute(f'DROP TABLE IF EXISTS "{table}" CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤è¡¨ {table} å¤±è´¥: {e}")
        
        # åˆ é™¤æ‰€æœ‰åºåˆ—
        for sequence in sequences:
            try:
                cursor.execute(f'DROP SEQUENCE IF EXISTS "{sequence}" CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤åºåˆ— {sequence} å¤±è´¥: {e}")
        
        # åˆ é™¤æ‰€æœ‰å‡½æ•°
        cursor.execute("""
            SELECT proname, oidvectortypes(proargtypes) 
            FROM pg_proc 
            WHERE pronamespace = 'public'::regnamespace
        """)
        functions = cursor.fetchall()
        
        for func_name, func_args in functions:
            try:
                cursor.execute(f'DROP FUNCTION IF EXISTS "{func_name}"({func_args}) CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤å‡½æ•° {func_name} å¤±è´¥: {e}")
        
        # åˆ é™¤æ‰€æœ‰è‡ªå®šä¹‰ç±»å‹
        cursor.execute("""
            SELECT typname FROM pg_type 
            WHERE typnamespace = 'public'::regnamespace 
            AND typtype = 'e'
        """)
        types = [row[0] for row in cursor.fetchall()]
        
        for type_name in types:
            try:
                cursor.execute(f'DROP TYPE IF EXISTS "{type_name}" CASCADE')
            except Exception as e:
                logger.warning(f"åˆ é™¤ç±»å‹ {type_name} å¤±è´¥: {e}")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        logger.info(f"âœ… äº‘ç«¯æ•°æ®åº“æ¸…ç†å®Œæˆ")
        logger.info(f"   - åˆ é™¤è¡¨: {len(tables)} ä¸ª")
        logger.info(f"   - åˆ é™¤åºåˆ—: {len(sequences)} ä¸ª")
        logger.info(f"   - åˆ é™¤è§†å›¾: {len(views)} ä¸ª")
        logger.info(f"   - åˆ é™¤å¤–é”®çº¦æŸ: {len(foreign_keys)} ä¸ª")
        logger.info(f"   - åˆ é™¤å‡½æ•°: {len(functions)} ä¸ª")
        logger.info(f"   - åˆ é™¤è‡ªå®šä¹‰ç±»å‹: {len(types)} ä¸ª")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†äº‘ç«¯æ•°æ®åº“å¤±è´¥: {str(e)}")
        return False

def export_local_schema():
    """å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    schema_filename = f"local_schema_{timestamp}.sql"
    schema_path = os.path.join('backups', schema_filename)
    
    try:
        logger.info("ğŸ”„ å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„...")
        
        local_config = parse_database_url(LOCAL_DB_URL)
        
        # æ„å»ºpg_dumpå‘½ä»¤ï¼ˆåªå¯¼å‡ºç»“æ„ï¼Œä¸æ¸…ç†ï¼‰
        cmd = [
            'pg_dump',
            '--host', local_config['host'],
            '--port', str(local_config['port']),
            '--username', local_config['username'],
            '--no-password',
            '--format', 'plain',
            '--schema-only',  # åªå¯¼å‡ºç»“æ„
            '--no-owner',
            '--no-privileges',
            '--encoding', 'UTF8',
            '--verbose',
            local_config['database']
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        if local_config['password']:
            env['PGPASSWORD'] = local_config['password']
        
        # æ‰§è¡Œå¯¼å‡ºå‘½ä»¤
        with open(schema_path, 'w') as f:
            result = subprocess.run(
                cmd,
                stdout=f,
                stderr=subprocess.PIPE,
                env=env,
                text=True
            )
        
        if result.returncode == 0:
            file_size = os.path.getsize(schema_path) / 1024  # KB
            logger.info(f"âœ… æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºæˆåŠŸ: {schema_filename}")
            logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
            logger.info(f"   å¯¼å‡ºè·¯å¾„: {schema_path}")
            return schema_path
        else:
            logger.error(f"âŒ æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥: {result.stderr}")
            if os.path.exists(schema_path):
                os.remove(schema_path)
            return None
            
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if os.path.exists(schema_path):
            os.remove(schema_path)
        return None

def sync_schema_to_cloud(schema_path):
    """åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“"""
    try:
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“...")
        
        cloud_config = parse_database_url(CLOUD_DB_URL)
        
        # æ„å»ºpsqlå‘½ä»¤
        cmd = [
            'psql',
            '--host', cloud_config['host'],
            '--port', str(cloud_config['port']),
            '--username', cloud_config['username'],
            '--dbname', cloud_config['database'],
            '--no-password',
            '--file', schema_path,
            '--echo-errors',
            '--set', 'ON_ERROR_STOP=1'
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['PGPASSWORD'] = cloud_config['password']
        
        # æ‰§è¡ŒåŒæ­¥å‘½ä»¤
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env=env,
            text=True
        )
        
        if result.returncode == 0:
            logger.info("âœ… æ•°æ®åº“ç»“æ„åŒæ­¥æˆåŠŸ")
            logger.info("   æ‰€æœ‰è¡¨ç»“æ„å·²æ›´æ–°åˆ°äº‘ç«¯æ•°æ®åº“")
            return True
        else:
            logger.error(f"âŒ æ•°æ®åº“ç»“æ„åŒæ­¥å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def verify_sync_result():
    """éªŒè¯åŒæ­¥ç»“æœ"""
    try:
        logger.info("ğŸ”„ éªŒè¯åŒæ­¥ç»“æœ...")
        
        # è¿æ¥æœ¬åœ°æ•°æ®åº“
        local_conn = psycopg2.connect(LOCAL_DB_URL)
        local_cursor = local_conn.cursor()
        
        # è¿æ¥äº‘ç«¯æ•°æ®åº“
        cloud_conn = psycopg2.connect(CLOUD_DB_URL)
        cloud_cursor = cloud_conn.cursor()
        
        # è·å–æœ¬åœ°è¡¨æ•°é‡
        local_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = 'public'
        """)
        local_table_count = local_cursor.fetchone()[0]
        
        # è·å–äº‘ç«¯è¡¨æ•°é‡
        cloud_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = 'public'
        """)
        cloud_table_count = cloud_cursor.fetchone()[0]
        
        # è·å–æœ¬åœ°åºåˆ—æ•°é‡
        local_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.sequences 
            WHERE sequence_schema = 'public'
        """)
        local_sequence_count = local_cursor.fetchone()[0]
        
        # è·å–äº‘ç«¯åºåˆ—æ•°é‡
        cloud_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.sequences 
            WHERE sequence_schema = 'public'
        """)
        cloud_sequence_count = cloud_cursor.fetchone()[0]
        
        # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
        key_tables = ['users', 'projects', 'quotations', 'products', 'companies']
        local_existing_tables = []
        cloud_existing_tables = []
        
        for table in key_tables:
            # æ£€æŸ¥æœ¬åœ°
            local_cursor.execute("""
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = %s
            """, (table,))
            if local_cursor.fetchone()[0] > 0:
                local_existing_tables.append(table)
            
            # æ£€æŸ¥äº‘ç«¯
            cloud_cursor.execute("""
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = %s
            """, (table,))
            if cloud_cursor.fetchone()[0] > 0:
                cloud_existing_tables.append(table)
        
        local_cursor.close()
        local_conn.close()
        cloud_cursor.close()
        cloud_conn.close()
        
        logger.info("ğŸ“Š åŒæ­¥ç»“æœéªŒè¯:")
        logger.info(f"   - æœ¬åœ°è¡¨æ•°é‡: {local_table_count}")
        logger.info(f"   - äº‘ç«¯è¡¨æ•°é‡: {cloud_table_count}")
        logger.info(f"   - æœ¬åœ°åºåˆ—æ•°é‡: {local_sequence_count}")
        logger.info(f"   - äº‘ç«¯åºåˆ—æ•°é‡: {cloud_sequence_count}")
        logger.info(f"   - æœ¬åœ°å…³é”®è¡¨: {len(local_existing_tables)}/{len(key_tables)}")
        logger.info(f"   - äº‘ç«¯å…³é”®è¡¨: {len(cloud_existing_tables)}/{len(key_tables)}")
        
        # æ£€æŸ¥åŒæ­¥æ˜¯å¦æˆåŠŸ
        tables_match = cloud_table_count == local_table_count
        sequences_match = cloud_sequence_count == local_sequence_count
        key_tables_match = len(cloud_existing_tables) == len(local_existing_tables)
        
        if tables_match and sequences_match and key_tables_match:
            logger.info("âœ… åŒæ­¥éªŒè¯æˆåŠŸ - ç»“æ„å®Œå…¨åŒ¹é…")
            return True
        else:
            if not tables_match:
                logger.warning(f"âš ï¸ è¡¨æ•°é‡ä¸åŒ¹é…: æœ¬åœ°{local_table_count} vs äº‘ç«¯{cloud_table_count}")
            if not sequences_match:
                logger.warning(f"âš ï¸ åºåˆ—æ•°é‡ä¸åŒ¹é…: æœ¬åœ°{local_sequence_count} vs äº‘ç«¯{cloud_sequence_count}")
            if not key_tables_match:
                logger.warning(f"âš ï¸ å…³é”®è¡¨ä¸åŒ¹é…: æœ¬åœ°{local_existing_tables} vs äº‘ç«¯{cloud_existing_tables}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ åŒæ­¥æœ¬åœ°æ•°æ®åº“ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ (æ”¹è¿›ç‰ˆæœ¬)")
    print("=" * 80)
    print("ğŸ“‹ ä»»åŠ¡è¯´æ˜:")
    print("   1. å¤‡ä»½äº‘ç«¯æ•°æ®åº“å†…å®¹")
    print("   2. æ¸…ç†äº‘ç«¯æ•°æ®åº“ç»“æ„")
    print("   3. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„")
    print("   4. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ï¼ˆä¸åŒ…å«æ•°æ®ï¼‰")
    print("=" * 80)
    
    # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
    print("\nğŸ“‹ æ­¥éª¤1: æµ‹è¯•æ•°æ®åº“è¿æ¥")
    if not test_database_connection(LOCAL_DB_URL, "æœ¬åœ°"):
        print("âŒ æœ¬åœ°æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    if not test_database_connection(CLOUD_DB_URL, "äº‘ç«¯"):
        print("âŒ äº‘ç«¯æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 2. å¤‡ä»½äº‘ç«¯æ•°æ®åº“
    print("\nğŸ“‹ æ­¥éª¤2: å¤‡ä»½äº‘ç«¯æ•°æ®åº“")
    backup_path = backup_cloud_database()
    if not backup_path:
        print("âŒ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 3. ç¡®è®¤æ¸…ç†æ“ä½œ
    print("\nğŸ“‹ æ­¥éª¤3: ç¡®è®¤æ¸…ç†å’ŒåŒæ­¥æ“ä½œ")
    print("âš ï¸ è­¦å‘Šï¼šå³å°†æ¸…ç†å¹¶è¦†ç›–äº‘ç«¯æ•°æ®åº“ç»“æ„ï¼")
    print(f"   - äº‘ç«¯æ•°æ®åº“: pma_db_ovs")
    print(f"   - å¤‡ä»½æ–‡ä»¶: {backup_path}")
    print("   - å°†åˆ é™¤äº‘ç«¯æ‰€æœ‰è¡¨ã€åºåˆ—ã€è§†å›¾ã€å‡½æ•°")
    print("   - ç„¶åå¯¼å…¥æœ¬åœ°æ•°æ®åº“ç»“æ„")
    
    confirm = input("\næ˜¯å¦ç»§ç»­åŒæ­¥ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ")
    if confirm != 'YES':
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return False
    
    # 4. æ¸…ç†äº‘ç«¯æ•°æ®åº“
    print("\nğŸ“‹ æ­¥éª¤4: æ¸…ç†äº‘ç«¯æ•°æ®åº“ç»“æ„")
    if not clean_cloud_database():
        print("âŒ äº‘ç«¯æ•°æ®åº“æ¸…ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 5. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„
    print("\nğŸ“‹ æ­¥éª¤5: å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„")
    schema_path = export_local_schema()
    if not schema_path:
        print("âŒ æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 6. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯
    print("\nğŸ“‹ æ­¥éª¤6: åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“")
    if not sync_schema_to_cloud(schema_path):
        print("âŒ æ•°æ®åº“ç»“æ„åŒæ­¥å¤±è´¥")
        return False
    
    # 7. éªŒè¯åŒæ­¥ç»“æœ
    print("\nğŸ“‹ æ­¥éª¤7: éªŒè¯åŒæ­¥ç»“æœ")
    if not verify_sync_result():
        print("âš ï¸ åŒæ­¥éªŒè¯æœ‰è­¦å‘Šï¼Œè¯·æ£€æŸ¥")
    
    print("\nğŸ‰ æ•°æ®åº“ç»“æ„åŒæ­¥å®Œæˆï¼")
    print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {backup_path}")
    print(f"ğŸ“ ç»“æ„æ–‡ä»¶ä¿å­˜åœ¨: {schema_path}")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        if success:
            print("\nâœ… ä»»åŠ¡å®Œæˆ")
            sys.exit(0)
        else:
            print("\nâŒ ä»»åŠ¡å¤±è´¥")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 