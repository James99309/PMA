#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¿ç§»æ–‡ä»¶åˆ†æå·¥å…·

æ­¤è„šæœ¬ç”¨äºåˆ†æFlask-Migrateç”Ÿæˆçš„æ•°æ®åº“è¿ç§»æ–‡ä»¶ï¼ŒæŸ¥æ‰¾æ½œåœ¨é—®é¢˜å’Œå†—ä½™ã€‚
å®ƒå¯ä»¥æ£€æµ‹è¿ç§»é“¾ä¸­çš„é—®é¢˜ï¼Œå¦‚å¾ªç¯ä¾èµ–ã€å­¤ç«‹è¿ç§»æ–‡ä»¶å’Œå†—ä½™æ“ä½œã€‚

ç”¨æ³•: python analyze_migrations.py
"""

import os
import re
import sys
import importlib.util
from datetime import datetime
from collections import defaultdict

# é…ç½®
MIGRATIONS_DIR = 'migrations/versions'  # è¿ç§»æ–‡ä»¶ç›®å½•
REPORT_FILE = 'unused/analysis/migration_analysis_report.md'  # æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶

def extract_migration_info(file_path):
    """ä»è¿ç§»æ–‡ä»¶ä¸­æå–å…³é”®ä¿¡æ¯
    
    å‚æ•°:
        file_path: è¿ç§»æ–‡ä»¶çš„è·¯å¾„
    
    è¿”å›:
        åŒ…å«è¿ç§»æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœè§£æå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # ä»æ–‡ä»¶åä¸­æå–è¿ç§»ID
        file_name = os.path.basename(file_path)
        migration_id = file_name.split('_')[0]
        
        # ä»æ–‡ä»¶å†…å®¹ä¸­æå–ä¿¡æ¯
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–ä¿®è®¢å· (revision)
        revision_match = re.search(r'revision\s*=\s*[\'"]([0-9a-f]+)[\'"]', content)
        revision = revision_match.group(1) if revision_match else None
        
        # æå–ä¾èµ– (down_revision)
        down_revision_match = re.search(r'down_revision\s*=\s*[\'"]?([0-9a-f]+|None)[\'"]?', content)
        down_revision = down_revision_match.group(1) if down_revision_match else None
        if down_revision == 'None':
            down_revision = None
        
        # æå–åˆ†æ”¯æ ‡è®° (branch_labels)
        branch_labels_match = re.search(r'branch_labels\s*=\s*([^#\n]+)', content)
        branch_labels = branch_labels_match.group(1).strip() if branch_labels_match else None
        
        # æå–æ—¶é—´æˆ³
        timestamp_match = re.search(r'Create Date: ([0-9-]+ [0-9:]+)', content)
        create_date = timestamp_match.group(1) if timestamp_match else None
        
        # æå–æ“ä½œç±»å‹
        operations = {
            'create_table': len(re.findall(r'op\.create_table', content)),
            'drop_table': len(re.findall(r'op\.drop_table', content)),
            'add_column': len(re.findall(r'op\.add_column', content)),
            'drop_column': len(re.findall(r'op\.drop_column', content)),
            'alter_column': len(re.findall(r'op\.alter_column', content)),
            'create_index': len(re.findall(r'op\.create_index', content)),
            'drop_index': len(re.findall(r'op\.drop_index', content)),
            'create_foreign_key': len(re.findall(r'op\.create_foreign_key', content)),
            'drop_foreign_key': len(re.findall(r'op\.drop_foreign_key', content)),
            'bulk_insert': len(re.findall(r'op\.bulk_insert', content)),
        }
        
        # æå–è¡¨å
        table_matches = re.findall(r'op\.create_table\([\'"]([^\'"]+)[\'"]', content)
        tables_created = list(set(table_matches))
        
        table_drop_matches = re.findall(r'op\.drop_table\([\'"]([^\'"]+)[\'"]', content)
        tables_dropped = list(set(table_drop_matches))
        
        # å°è¯•æå–è¿ç§»è¯´æ˜/æ³¨é‡Š
        comment_match = re.search(r'"""(.+?)"""', content, re.DOTALL)
        comment = comment_match.group(1).strip() if comment_match else ""
        
        return {
            'file_name': file_name,
            'file_path': file_path,
            'migration_id': migration_id,
            'revision': revision,
            'down_revision': down_revision,
            'branch_labels': branch_labels,
            'create_date': create_date,
            'operations': operations,
            'tables_created': tables_created,
            'tables_dropped': tables_dropped,
            'comment': comment
        }
    except Exception as e:
        print(f"è§£æè¿ç§»æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return None

def build_migration_tree(migrations):
    """æ„å»ºè¿ç§»æ ‘ï¼Œåˆ†æè¿ç§»ä¹‹é—´çš„å…³ç³»
    
    å‚æ•°:
        migrations: åŒ…å«æ‰€æœ‰è¿ç§»ä¿¡æ¯çš„åˆ—è¡¨
    
    è¿”å›:
        è¿ç§»æ ‘çš„å­—å…¸è¡¨ç¤º
    """
    tree = {}
    for migration in migrations:
        tree[migration['revision']] = {
            'down_revision': migration['down_revision'],
            'children': [],
            'info': migration
        }
    
    # è¿æ¥çˆ¶å­å…³ç³»
    for revision, node in tree.items():
        if node['down_revision'] in tree:
            tree[node['down_revision']]['children'].append(revision)
    
    return tree

def check_for_issues(migrations, tree):
    """æ£€æŸ¥è¿ç§»ä¸­çš„æ½œåœ¨é—®é¢˜
    
    å‚æ•°:
        migrations: è¿ç§»ä¿¡æ¯åˆ—è¡¨
        tree: è¿ç§»æ ‘
    
    è¿”å›:
        å‘ç°çš„é—®é¢˜åˆ—è¡¨
    """
    issues = []
    
    # æ£€æŸ¥å¤šä¸ªå¤´èŠ‚ç‚¹
    heads = [m for m in migrations if not any(m['revision'] == x['down_revision'] for x in migrations)]
    if len(heads) > 1:
        head_revisions = [h['revision'] for h in heads]
        issues.append({
            'type': 'multiple_heads',
            'severity': 'high',
            'description': f"å‘ç°å¤šä¸ªå¤´èŠ‚ç‚¹: {', '.join(head_revisions)}",
            'migrations': head_revisions
        })
    
    # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰ä¸ä¸»é“¾ç›¸è¿ï¼‰
    root_nodes = [m for m in migrations if m['down_revision'] is None]
    if len(root_nodes) > 1:
        root_revisions = [r['revision'] for r in root_nodes]
        issues.append({
            'type': 'multiple_roots',
            'severity': 'high',
            'description': f"å‘ç°å¤šä¸ªæ ¹èŠ‚ç‚¹: {', '.join(root_revisions)}",
            'migrations': root_revisions
        })
    
    # æ£€æŸ¥è¿‘æœŸæœ‰å†²çªçš„æ“ä½œï¼ˆæ¯”å¦‚åˆ›å»ºå’Œåˆ é™¤åŒä¸€å¼ è¡¨ï¼‰
    table_operations = defaultdict(list)
    for m in migrations:
        for table in m['tables_created']:
            table_operations[table].append({
                'operation': 'create',
                'migration': m['revision'],
                'date': m['create_date']
            })
        for table in m['tables_dropped']:
            table_operations[table].append({
                'operation': 'drop',
                'migration': m['revision'],
                'date': m['create_date']
            })
    
    for table, operations in table_operations.items():
        if len(operations) > 1:
            # æŒ‰æ—¶é—´æ’åºæ“ä½œ
            try:
                sorted_ops = sorted(operations, key=lambda x: datetime.strptime(x['date'], '%Y-%m-%d %H:%M:%S'))
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åˆ›å»ºååˆåˆ é™¤çš„æ¨¡å¼
                for i in range(len(sorted_ops) - 1):
                    if sorted_ops[i]['operation'] == 'create' and sorted_ops[i+1]['operation'] == 'drop':
                        issues.append({
                            'type': 'table_created_then_dropped',
                            'severity': 'medium',
                            'description': f"è¡¨ '{table}' åœ¨è¿ç§» {sorted_ops[i]['migration']} ä¸­åˆ›å»ºï¼Œéšååœ¨è¿ç§» {sorted_ops[i+1]['migration']} ä¸­åˆ é™¤",
                            'migrations': [sorted_ops[i]['migration'], sorted_ops[i+1]['migration']]
                        })
            except Exception as e:
                print(f"æ— æ³•åˆ†æè¡¨ {table} çš„æ“ä½œ: {e}")
    
    return issues

def analyze_migrations():
    """åˆ†ææ‰€æœ‰è¿ç§»æ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š"""
    print("å¼€å§‹åˆ†æè¿ç§»æ–‡ä»¶...")
    
    # ç¡®ä¿è¿ç§»ç›®å½•å­˜åœ¨
    if not os.path.exists(MIGRATIONS_DIR):
        print(f"é”™è¯¯: è¿ç§»ç›®å½• '{MIGRATIONS_DIR}' ä¸å­˜åœ¨")
        return
    
    # è·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶
    migration_files = []
    for file in os.listdir(MIGRATIONS_DIR):
        if file.endswith('.py') and not file.startswith('__'):
            migration_files.append(os.path.join(MIGRATIONS_DIR, file))
    
    print(f"æ‰¾åˆ° {len(migration_files)} ä¸ªè¿ç§»æ–‡ä»¶")
    
    # è§£æè¿ç§»æ–‡ä»¶
    migrations = []
    for file_path in migration_files:
        info = extract_migration_info(file_path)
        if info:
            migrations.append(info)
    
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
    try:
        migrations.sort(key=lambda x: datetime.strptime(x['create_date'], '%Y-%m-%d %H:%M:%S') if x['create_date'] else datetime.min)
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•æŒ‰æ—¥æœŸæ’åºè¿ç§»: {e}")
        # å°è¯•æŒ‰æ–‡ä»¶åæ’åºä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        migrations.sort(key=lambda x: x['file_name'])
    
    # æ„å»ºè¿ç§»æ ‘
    tree = build_migration_tree(migrations)
    
    # æ£€æŸ¥é—®é¢˜
    issues = check_for_issues(migrations, tree)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = []
    report.append("# æ•°æ®åº“è¿ç§»åˆ†ææŠ¥å‘Š")
    report.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"\n## æ¦‚å†µ")
    report.append(f"\n- æ€»è¿ç§»æ•°é‡: {len(migrations)}")
    
    # è·å–æœ€æ—©å’Œæœ€æ–°çš„è¿ç§»
    if migrations:
        earliest = migrations[0]
        latest = migrations[-1]
        report.append(f"- æœ€æ—©è¿ç§»: {earliest['file_name']} ({earliest['create_date']})")
        report.append(f"- æœ€æ–°è¿ç§»: {latest['file_name']} ({latest['create_date']})")
    
    # ç»Ÿè®¡æ“ä½œç±»å‹
    operation_counts = defaultdict(int)
    for m in migrations:
        for op_type, count in m['operations'].items():
            operation_counts[op_type] += count
    
    report.append("\n## æ“ä½œç»Ÿè®¡")
    for op_type, count in sorted(operation_counts.items(), key=lambda x: x[1], reverse=True):
        report.append(f"\n- {op_type}: {count}")
    
    # æŠ¥å‘Šé—®é¢˜
    if issues:
        report.append("\n## æ£€æµ‹åˆ°çš„é—®é¢˜")
        for issue in issues:
            severity_mark = {
                'high': 'ğŸ”´',
                'medium': 'ğŸŸ ',
                'low': 'ğŸŸ¡'
            }.get(issue['severity'], 'âšª')
            
            report.append(f"\n### {severity_mark} {issue['type']}")
            report.append(f"\n{issue['description']}")
            report.append(f"\nç›¸å…³è¿ç§»: {', '.join(issue['migrations'])}")
    else:
        report.append("\n## æ£€æµ‹åˆ°çš„é—®é¢˜\n\næœªå‘ç°é—®é¢˜ï¼Œè¿ç§»é“¾å®Œæ•´ã€‚")
    
    # è¿ç§»åˆ—è¡¨
    report.append("\n## è¿ç§»åˆ—è¡¨")
    for m in migrations:
        report.append(f"\n### {m['file_name']}")
        report.append(f"\n- ä¿®è®¢å·: {m['revision']}")
        report.append(f"- ä¾èµ–ä¿®è®¢: {m['down_revision'] or 'None (æ ¹èŠ‚ç‚¹)'}")
        report.append(f"- åˆ›å»ºæ—¶é—´: {m['create_date']}")
        
        # æ·»åŠ æ“ä½œæ‘˜è¦
        active_ops = {k: v for k, v in m['operations'].items() if v > 0}
        if active_ops:
            report.append(f"- æ“ä½œ: {', '.join([f'{k} ({v})' for k, v in active_ops.items()])}")
        else:
            report.append("- æ“ä½œ: æ— æ“ä½œæˆ–æ— æ³•è§£æ")
        
        # æ·»åŠ è¡¨æ“ä½œ
        if m['tables_created']:
            report.append(f"- åˆ›å»ºçš„è¡¨: {', '.join(m['tables_created'])}")
        if m['tables_dropped']:
            report.append(f"- åˆ é™¤çš„è¡¨: {', '.join(m['tables_dropped'])}")
        
        # æ·»åŠ æ³¨é‡Š/è¯´æ˜
        if m['comment']:
            comment_summary = m['comment']
            if len(comment_summary) > 100:
                comment_summary = comment_summary[:97] + "..."
            report.append(f"- è¯´æ˜: {comment_summary}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_dir = os.path.dirname(REPORT_FILE)
    if not os.path.exists(report_dir):
        os.makedirs(report_dir)
        
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {REPORT_FILE}")
    
    return {
        'migrations': migrations,
        'issues': issues,
        'tree': tree
    }

def main():
    """ä¸»å‡½æ•°"""
    try:
        result = analyze_migrations()
        if result:
            issues_count = len(result['issues'])
            print(f"åˆ†æç»“æœ: æ‰¾åˆ° {len(result['migrations'])} ä¸ªè¿ç§»æ–‡ä»¶ï¼Œæ£€æµ‹åˆ° {issues_count} ä¸ªé—®é¢˜")
            
            if issues_count > 0:
                print("\næ£€æµ‹åˆ°çš„é—®é¢˜:")
                for issue in result['issues']:
                    print(f"- {issue['description']}")
    except Exception as e:
        print(f"æ‰§è¡Œåˆ†ææ—¶å‡ºé”™: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 