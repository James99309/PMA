#!/usr/bin/env python3
"""
å°†æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ° pma_db_ovs æ•°æ®åº“
å…ˆå¤‡ä»½ç›®æ ‡æ•°æ®åº“ï¼Œç„¶åå®‰å…¨åœ°åŒæ­¥ç»“æ„

Created: 2025-06-27
Author: Assistant
Purpose: å®‰å…¨åœ°å°†æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ°pma_db_ovsæ•°æ®åº“
"""

import os
import sys
import psycopg2
import json
from datetime import datetime
from urllib.parse import urlparse

# æ•°æ®åº“è¿æ¥é…ç½®
LOCAL_DB_URL = os.getenv('DATABASE_URL', 'postgresql://nijie:@localhost:5432/pma_local')
OVS_DB_URL = 'postgresql://pma_db_ovs_user:oUKdxwqXDvCrgkg3fkZ33axXgDF21D51@dpg-d170laodl3ps739trgp0-a.singapore-postgres.render.com/pma_db_ovs'

def parse_db_url(db_url):
    """è§£ææ•°æ®åº“URL"""
    parsed = urlparse(db_url)
    return {
        'host': parsed.hostname,
        'port': parsed.port or 5432,
        'database': parsed.path[1:],
        'user': parsed.username,
        'password': parsed.password
    }

def get_db_connection(db_url):
    """è·å–æ•°æ®åº“è¿æ¥"""
    db_config = parse_db_url(db_url)
    return psycopg2.connect(**db_config)

def backup_ovs_database():
    """å¤‡ä»½OVSæ•°æ®åº“"""
    print("=== å¤‡ä»½pma_db_ovsæ•°æ®åº“ ===")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    backup_dir = "ovs_db_backups"
    os.makedirs(backup_dir, exist_ok=True)
    
    # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"{backup_dir}/pma_db_ovs_backup_{timestamp}.sql"
    
    # è§£ææ•°æ®åº“é…ç½®
    db_config = parse_db_url(OVS_DB_URL)
    
    # ä½¿ç”¨pg_dumpå¤‡ä»½
    dump_cmd = [
        'pg_dump',
        f"--host={db_config['host']}",
        f"--port={db_config['port']}",
        f"--username={db_config['user']}",
        f"--dbname={db_config['database']}",
        '--verbose',
        '--clean',
        '--no-owner',
        '--no-privileges',
        '--format=plain',
        f"--file={backup_file}"
    ]
    
    # è®¾ç½®å¯†ç ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env['PGPASSWORD'] = db_config['password']
    
    try:
        import subprocess
        print(f"æ­£åœ¨å¤‡ä»½pma_db_ovsæ•°æ®åº“åˆ°: {backup_file}")
        result = subprocess.run(dump_cmd, env=env, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… pma_db_ovsæ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_file}")
            
            # åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
            info_file = f"{backup_dir}/pma_db_ovs_backup_info_{timestamp}.md"
            with open(info_file, 'w', encoding='utf-8') as f:
                f.write(f"# pma_db_ovsæ•°æ®åº“å¤‡ä»½ä¿¡æ¯\n\n")
                f.write(f"**å¤‡ä»½æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**æºæ•°æ®åº“**: {db_config['host']}:{db_config['port']}/{db_config['database']}\n")
                f.write(f"**å¤‡ä»½æ–‡ä»¶**: {backup_file}\n")
                f.write(f"**å¤‡ä»½å¤§å°**: {os.path.getsize(backup_file)} å­—èŠ‚\n\n")
                f.write("## å¤‡ä»½è¯´æ˜\n")
                f.write("- è¿™æ˜¯åœ¨æ•°æ®åº“ç»“æ„åŒæ­¥å‰çš„å®Œæ•´å¤‡ä»½\n")
                f.write("- åŒ…å«æ‰€æœ‰è¡¨ç»“æ„å’Œæ•°æ®\n")
                f.write("- å¯ç”¨äºç´§æ€¥æ¢å¤\n")
            
            return backup_file
        else:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
        return None

def get_table_columns(db_url):
    """è·å–æ•°æ®åº“è¡¨çš„åˆ—ä¿¡æ¯"""
    conn = get_db_connection(db_url)
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT 
            t.table_name,
            c.column_name,
            c.data_type,
            c.character_maximum_length,
            c.numeric_precision,
            c.numeric_scale,
            c.is_nullable,
            c.column_default,
            c.ordinal_position
        FROM information_schema.tables t
        JOIN information_schema.columns c ON t.table_name = c.table_name
        WHERE t.table_schema = 'public' AND c.table_schema = 'public'
        ORDER BY t.table_name, c.ordinal_position;
    """)
    
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    
    # æŒ‰è¡¨ç»„ç»‡æ•°æ®
    tables = {}
    for row in results:
        table_name = row[0]
        if table_name not in tables:
            tables[table_name] = []
        tables[table_name].append({
            'column_name': row[1],
            'data_type': row[2],
            'character_maximum_length': row[3],
            'numeric_precision': row[4],
            'numeric_scale': row[5],
            'is_nullable': row[6],
            'column_default': row[7],
            'ordinal_position': row[8]
        })
    
    return tables

def get_table_constraints(db_url):
    """è·å–è¡¨çš„çº¦æŸä¿¡æ¯"""
    conn = get_db_connection(db_url)
    cursor = conn.cursor()
    
    # è·å–ä¸»é”®ä¿¡æ¯
    cursor.execute("""
        SELECT 
            tc.table_name,
            kcu.column_name,
            tc.constraint_type
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu 
            ON tc.constraint_name = kcu.constraint_name
        WHERE tc.table_schema = 'public'
          AND tc.constraint_type = 'PRIMARY KEY'
        ORDER BY tc.table_name, kcu.ordinal_position;
    """)
    
    primary_keys = {}
    for row in cursor.fetchall():
        table_name, column_name, constraint_type = row
        if table_name not in primary_keys:
            primary_keys[table_name] = []
        primary_keys[table_name].append(column_name)
    
    # è·å–å¤–é”®ä¿¡æ¯
    cursor.execute("""
        SELECT 
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu 
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage ccu 
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.table_schema = 'public'
          AND tc.constraint_type = 'FOREIGN KEY';
    """)
    
    foreign_keys = {}
    for row in cursor.fetchall():
        table_name, column_name, foreign_table, foreign_column = row
        if table_name not in foreign_keys:
            foreign_keys[table_name] = []
        foreign_keys[table_name].append({
            'column': column_name,
            'foreign_table': foreign_table,
            'foreign_column': foreign_column
        })
    
    cursor.close()
    conn.close()
    
    return primary_keys, foreign_keys

def analyze_database_differences():
    """åˆ†ææœ¬åœ°å’ŒOVSæ•°æ®åº“çš„å·®å¼‚"""
    print("=== åˆ†ææ•°æ®åº“ç»“æ„å·®å¼‚ ===")
    
    # è·å–æœ¬åœ°æ•°æ®åº“ç»“æ„
    print("æ­£åœ¨è·å–æœ¬åœ°æ•°æ®åº“ç»“æ„...")
    local_tables = get_table_columns(LOCAL_DB_URL)
    local_pk, local_fk = get_table_constraints(LOCAL_DB_URL)
    print(f"âœ… æœ¬åœ°æ•°æ®åº“: {len(local_tables)} ä¸ªè¡¨")
    
    # è·å–OVSæ•°æ®åº“ç»“æ„
    print("æ­£åœ¨è·å–pma_db_ovsæ•°æ®åº“ç»“æ„...")
    try:
        ovs_tables = get_table_columns(OVS_DB_URL)
        ovs_pk, ovs_fk = get_table_constraints(OVS_DB_URL)
        print(f"âœ… pma_db_ovsæ•°æ®åº“: {len(ovs_tables)} ä¸ªè¡¨")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥pma_db_ovsæ•°æ®åº“: {str(e)}")
        return None
    
    # åˆ†æå·®å¼‚
    differences = {
        'missing_tables': [],      # OVSç¼ºå¤±çš„è¡¨
        'extra_tables': [],        # OVSå¤šå‡ºçš„è¡¨
        'table_differences': {}    # è¡¨ç»“æ„å·®å¼‚
    }
    
    local_table_names = set(local_tables.keys())
    ovs_table_names = set(ovs_tables.keys())
    
    # æ‰¾å‡ºç¼ºå¤±å’Œå¤šä½™çš„è¡¨
    differences['missing_tables'] = list(local_table_names - ovs_table_names)
    differences['extra_tables'] = list(ovs_table_names - local_table_names)
    
    print(f"\nğŸ“Š å·®å¼‚åˆ†æç»“æœ:")
    print(f"  - OVSç¼ºå¤±è¡¨: {len(differences['missing_tables'])} ä¸ª")
    print(f"  - OVSå¤šä½™è¡¨: {len(differences['extra_tables'])} ä¸ª")
    
    if differences['missing_tables']:
        print(f"  ç¼ºå¤±çš„è¡¨: {', '.join(differences['missing_tables'])}")
    
    # å¯¹æ¯”å…±åŒè¡¨çš„åˆ—å·®å¼‚
    common_tables = local_table_names & ovs_table_names
    for table_name in common_tables:
        local_columns = {col['column_name']: col for col in local_tables[table_name]}
        ovs_columns = {col['column_name']: col for col in ovs_tables[table_name]}
        
        table_diff = {
            'missing_columns': [],
            'extra_columns': [],
            'column_differences': []
        }
        
        # æ‰¾å‡ºç¼ºå¤±å’Œå¤šä½™çš„åˆ—
        local_col_names = set(local_columns.keys())
        ovs_col_names = set(ovs_columns.keys())
        
        table_diff['missing_columns'] = list(local_col_names - ovs_col_names)
        table_diff['extra_columns'] = list(ovs_col_names - local_col_names)
        
        # å¯¹æ¯”ç›¸åŒåˆ—çš„å±æ€§å·®å¼‚
        common_columns = local_col_names & ovs_col_names
        for col_name in common_columns:
            local_col = local_columns[col_name]
            ovs_col = ovs_columns[col_name]
            
            # æ¯”è¾ƒå…³é”®å±æ€§
            if (local_col['data_type'] != ovs_col['data_type'] or
                local_col['is_nullable'] != ovs_col['is_nullable'] or
                local_col['character_maximum_length'] != ovs_col['character_maximum_length']):
                table_diff['column_differences'].append({
                    'column': col_name,
                    'local': local_col,
                    'ovs': ovs_col
                })
        
        # åªæœ‰å­˜åœ¨å·®å¼‚æ—¶æ‰è®°å½•
        if (table_diff['missing_columns'] or 
            table_diff['extra_columns'] or 
            table_diff['column_differences']):
            differences['table_differences'][table_name] = table_diff
    
    if differences['table_differences']:
        print(f"  - è¡¨ç»“æ„å·®å¼‚: {len(differences['table_differences'])} ä¸ªè¡¨")
    
    return differences, local_tables, local_pk, local_fk

def generate_create_table_sql(table_name, columns, primary_keys):
    """ç”Ÿæˆåˆ›å»ºè¡¨çš„SQL"""
    col_definitions = []
    
    for col in columns:
        col_name = col['column_name']
        data_type = col['data_type']
        
        # å¤„ç†æ•°æ®ç±»å‹
        if col['character_maximum_length']:
            data_type += f"({col['character_maximum_length']})"
        elif col['numeric_precision'] and col['numeric_scale'] is not None:
            data_type += f"({col['numeric_precision']},{col['numeric_scale']})"
        elif col['numeric_precision']:
            data_type += f"({col['numeric_precision']})"
        
        # å¤„ç†å¯ç©ºæ€§
        nullable = "" if col['is_nullable'] == 'YES' else " NOT NULL"
        
        # å¤„ç†é»˜è®¤å€¼
        default = ""
        if col['column_default']:
            default = f" DEFAULT {col['column_default']}"
        
        col_definitions.append(f"  {col_name} {data_type}{nullable}{default}")
    
    # æ·»åŠ ä¸»é”®
    if table_name in primary_keys and primary_keys[table_name]:
        pk_cols = ', '.join(primary_keys[table_name])
        col_definitions.append(f"  PRIMARY KEY ({pk_cols})")
    
    return f"CREATE TABLE {table_name} (\n" + ",\n".join(col_definitions) + "\n);"

def generate_sync_sql(differences, local_tables, local_pk, local_fk):
    """ç”ŸæˆåŒæ­¥SQLè¯­å¥"""
    print("\n=== ç”ŸæˆåŒæ­¥SQL ===")
    
    sql_statements = []
    
    # 1. åˆ›å»ºç¼ºå¤±çš„è¡¨
    for table_name in differences['missing_tables']:
        print(f"  ç”Ÿæˆåˆ›å»ºè¡¨SQL: {table_name}")
        columns = local_tables[table_name]
        create_sql = generate_create_table_sql(table_name, columns, local_pk)
        sql_statements.append(create_sql)
    
    # 2. æ·»åŠ ç¼ºå¤±çš„åˆ—
    for table_name, table_diff in differences['table_differences'].items():
        for col_name in table_diff['missing_columns']:
            print(f"  ç”Ÿæˆæ·»åŠ åˆ—SQL: {table_name}.{col_name}")
            # ä»æœ¬åœ°ç»“æ„ä¸­æ‰¾åˆ°åˆ—å®šä¹‰
            local_columns = {col['column_name']: col for col in local_tables[table_name]}
            col_info = local_columns[col_name]
            
            data_type = col_info['data_type']
            if col_info['character_maximum_length']:
                data_type += f"({col_info['character_maximum_length']})"
            elif col_info['numeric_precision'] and col_info['numeric_scale'] is not None:
                data_type += f"({col_info['numeric_precision']},{col_info['numeric_scale']})"
            elif col_info['numeric_precision']:
                data_type += f"({col_info['numeric_precision']})"
            
            nullable = "" if col_info['is_nullable'] == 'YES' else " NOT NULL"
            default = f" DEFAULT {col_info['column_default']}" if col_info['column_default'] else ""
            
            alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {col_name} {data_type}{nullable}{default};"
            sql_statements.append(alter_sql)
    
    return sql_statements

def execute_sync_sql(sql_statements):
    """æ‰§è¡ŒåŒæ­¥SQL"""
    if not sql_statements:
        print("âœ… æ— éœ€æ‰§è¡ŒåŒæ­¥SQL")
        return True
    
    print(f"\n=== å‡†å¤‡æ‰§è¡Œ {len(sql_statements)} æ¡åŒæ­¥SQL ===")
    
    # æ˜¾ç¤ºSQLé¢„è§ˆ
    print("\nå°†è¦æ‰§è¡Œçš„SQLè¯­å¥:")
    for i, sql in enumerate(sql_statements, 1):
        # åªæ˜¾ç¤ºå‰å‡ è¡Œï¼Œé¿å…è¾“å‡ºè¿‡é•¿
        if i <= 10:
            print(f"{i:2d}. {sql[:100]}{'...' if len(sql) > 100 else ''}")
        elif i == 11:
            print(f"    ... è¿˜æœ‰ {len(sql_statements) - 10} æ¡SQLè¯­å¥")
    
    # ç¡®è®¤æ‰§è¡Œ
    print(f"\nâš ï¸ æ³¨æ„ï¼šè¿™äº›æ“ä½œå°†ä¿®æ”¹pma_db_ovsæ•°æ®åº“ç»“æ„")
    print("è¿™ä¼šæ·»åŠ ç¼ºå¤±çš„è¡¨å’Œåˆ—ï¼Œä¸ä¼šåˆ é™¤ç°æœ‰æ•°æ®")
    
    confirm = input(f"\næ˜¯å¦æ‰§è¡Œä»¥ä¸Š {len(sql_statements)} æ¡SQLè¯­å¥ï¼Ÿ(y/N): ")
    if confirm.lower() != 'y':
        print("âŒ ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ")
        return False
    
    try:
        print("\næ­£åœ¨è¿æ¥pma_db_ovsæ•°æ®åº“...")
        conn = get_db_connection(OVS_DB_URL)
        cursor = conn.cursor()
        
        print("å¼€å§‹æ‰§è¡ŒåŒæ­¥SQL...")
        success_count = 0
        
        for i, sql in enumerate(sql_statements, 1):
            try:
                print(f"æ‰§è¡Œç¬¬ {i:2d} æ¡SQL: ", end="", flush=True)
                cursor.execute(sql)
                conn.commit()
                print("âœ… æˆåŠŸ")
                success_count += 1
            except Exception as e:
                print(f"âŒ å¤±è´¥: {str(e)}")
                conn.rollback()
                # ç»§ç»­æ‰§è¡Œå…¶ä»–SQL
        
        cursor.close()
        conn.close()
        
        print(f"\nğŸ“Š æ‰§è¡Œç»“æœ: {success_count}/{len(sql_statements)} æ¡SQLæˆåŠŸæ‰§è¡Œ")
        
        if success_count == len(sql_statements):
            print("ğŸ‰ æ‰€æœ‰åŒæ­¥SQLæ‰§è¡ŒæˆåŠŸï¼")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†åŒæ­¥SQLæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return False
        
    except Exception as e:
        print(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=== æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ°pma_db_ovs ===")
    print(f"æºæ•°æ®åº“: {LOCAL_DB_URL}")
    print(f"ç›®æ ‡æ•°æ®åº“: {OVS_DB_URL.replace(OVS_DB_URL.split('@')[0].split(':')[-1], '***')}")
    print()
    
    try:
        # 1. å¤‡ä»½OVSæ•°æ®åº“
        backup_file = backup_ovs_database()
        if not backup_file:
            print("âŒ å¤‡ä»½å¤±è´¥ï¼Œå»ºè®®ä¿®å¤å¤‡ä»½é—®é¢˜åå†åŒæ­¥")
            confirm = input("æ˜¯å¦è·³è¿‡å¤‡ä»½ç»§ç»­åŒæ­¥ï¼Ÿ(y/N): ")
            if confirm.lower() != 'y':
                return
        print()
        
        # 2. åˆ†ææ•°æ®åº“å·®å¼‚
        analysis_result = analyze_database_differences()
        if analysis_result is None:
            return
        
        differences, local_tables, local_pk, local_fk = analysis_result
        
        # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
        total_changes = (len(differences['missing_tables']) + 
                        sum(len(td['missing_columns']) for td in differences['table_differences'].values()))
        
        if total_changes == 0:
            print("\nâœ… pma_db_ovsæ•°æ®åº“ç»“æ„å·²ç»æ˜¯æœ€æ–°çš„ï¼Œæ— éœ€åŒæ­¥")
            return
        
        print(f"\nğŸ“‹ éœ€è¦åŒæ­¥ {total_changes} é¡¹æ›´æ”¹")
        
        # 4. ç”ŸæˆåŒæ­¥SQL
        sql_statements = generate_sync_sql(differences, local_tables, local_pk, local_fk)
        
        # 5. ä¿å­˜SQLåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sql_file = f"pma_db_ovs_sync_{timestamp}.sql"
        
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write("-- pma_db_ovsæ•°æ®åº“ç»“æ„åŒæ­¥SQL\n")
            f.write(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"-- æºæ•°æ®åº“: {LOCAL_DB_URL}\n")
            f.write(f"-- ç›®æ ‡æ•°æ®åº“: pma_db_ovs\n\n")
            
            for sql in sql_statements:
                f.write(sql + "\n\n")
        
        print(f"\nğŸ“„ åŒæ­¥SQLå·²ä¿å­˜åˆ°: {sql_file}")
        
        # 6. æ‰§è¡ŒåŒæ­¥
        success = execute_sync_sql(sql_statements)
        
        if success:
            print(f"\nğŸ‰ æ•°æ®åº“ç»“æ„åŒæ­¥å®Œæˆï¼")
            if backup_file:
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
            print(f"ğŸ“„ åŒæ­¥SQL: {sql_file}")
        else:
            print(f"\nâš ï¸ æ•°æ®åº“åŒæ­¥æœªå®Œå…¨æˆåŠŸ")
            if backup_file:
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
            print(f"ğŸ“„ åŒæ­¥SQL: {sql_file}")
    
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main() 
"""
å°†æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ° pma_db_ovs æ•°æ®åº“
å…ˆå¤‡ä»½ç›®æ ‡æ•°æ®åº“ï¼Œç„¶åå®‰å…¨åœ°åŒæ­¥ç»“æ„

Created: 2025-06-27
Author: Assistant
Purpose: å®‰å…¨åœ°å°†æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ°pma_db_ovsæ•°æ®åº“
"""

import os
import sys
import psycopg2
import json
from datetime import datetime
from urllib.parse import urlparse

# æ•°æ®åº“è¿æ¥é…ç½®
LOCAL_DB_URL = os.getenv('DATABASE_URL', 'postgresql://nijie:@localhost:5432/pma_local')
OVS_DB_URL = 'postgresql://pma_db_ovs_user:oUKdxwqXDvCrgkg3fkZ33axXgDF21D51@dpg-d170laodl3ps739trgp0-a.singapore-postgres.render.com/pma_db_ovs'

def parse_db_url(db_url):
    """è§£ææ•°æ®åº“URL"""
    parsed = urlparse(db_url)
    return {
        'host': parsed.hostname,
        'port': parsed.port or 5432,
        'database': parsed.path[1:],
        'user': parsed.username,
        'password': parsed.password
    }

def get_db_connection(db_url):
    """è·å–æ•°æ®åº“è¿æ¥"""
    db_config = parse_db_url(db_url)
    return psycopg2.connect(**db_config)

def backup_ovs_database():
    """å¤‡ä»½OVSæ•°æ®åº“"""
    print("=== å¤‡ä»½pma_db_ovsæ•°æ®åº“ ===")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    backup_dir = "ovs_db_backups"
    os.makedirs(backup_dir, exist_ok=True)
    
    # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"{backup_dir}/pma_db_ovs_backup_{timestamp}.sql"
    
    # è§£ææ•°æ®åº“é…ç½®
    db_config = parse_db_url(OVS_DB_URL)
    
    # ä½¿ç”¨pg_dumpå¤‡ä»½
    dump_cmd = [
        'pg_dump',
        f"--host={db_config['host']}",
        f"--port={db_config['port']}",
        f"--username={db_config['user']}",
        f"--dbname={db_config['database']}",
        '--verbose',
        '--clean',
        '--no-owner',
        '--no-privileges',
        '--format=plain',
        f"--file={backup_file}"
    ]
    
    # è®¾ç½®å¯†ç ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env['PGPASSWORD'] = db_config['password']
    
    try:
        import subprocess
        print(f"æ­£åœ¨å¤‡ä»½pma_db_ovsæ•°æ®åº“åˆ°: {backup_file}")
        result = subprocess.run(dump_cmd, env=env, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… pma_db_ovsæ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_file}")
            
            # åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
            info_file = f"{backup_dir}/pma_db_ovs_backup_info_{timestamp}.md"
            with open(info_file, 'w', encoding='utf-8') as f:
                f.write(f"# pma_db_ovsæ•°æ®åº“å¤‡ä»½ä¿¡æ¯\n\n")
                f.write(f"**å¤‡ä»½æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**æºæ•°æ®åº“**: {db_config['host']}:{db_config['port']}/{db_config['database']}\n")
                f.write(f"**å¤‡ä»½æ–‡ä»¶**: {backup_file}\n")
                f.write(f"**å¤‡ä»½å¤§å°**: {os.path.getsize(backup_file)} å­—èŠ‚\n\n")
                f.write("## å¤‡ä»½è¯´æ˜\n")
                f.write("- è¿™æ˜¯åœ¨æ•°æ®åº“ç»“æ„åŒæ­¥å‰çš„å®Œæ•´å¤‡ä»½\n")
                f.write("- åŒ…å«æ‰€æœ‰è¡¨ç»“æ„å’Œæ•°æ®\n")
                f.write("- å¯ç”¨äºç´§æ€¥æ¢å¤\n")
            
            return backup_file
        else:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
        return None

def get_table_columns(db_url):
    """è·å–æ•°æ®åº“è¡¨çš„åˆ—ä¿¡æ¯"""
    conn = get_db_connection(db_url)
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT 
            t.table_name,
            c.column_name,
            c.data_type,
            c.character_maximum_length,
            c.numeric_precision,
            c.numeric_scale,
            c.is_nullable,
            c.column_default,
            c.ordinal_position
        FROM information_schema.tables t
        JOIN information_schema.columns c ON t.table_name = c.table_name
        WHERE t.table_schema = 'public' AND c.table_schema = 'public'
        ORDER BY t.table_name, c.ordinal_position;
    """)
    
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    
    # æŒ‰è¡¨ç»„ç»‡æ•°æ®
    tables = {}
    for row in results:
        table_name = row[0]
        if table_name not in tables:
            tables[table_name] = []
        tables[table_name].append({
            'column_name': row[1],
            'data_type': row[2],
            'character_maximum_length': row[3],
            'numeric_precision': row[4],
            'numeric_scale': row[5],
            'is_nullable': row[6],
            'column_default': row[7],
            'ordinal_position': row[8]
        })
    
    return tables

def get_table_constraints(db_url):
    """è·å–è¡¨çš„çº¦æŸä¿¡æ¯"""
    conn = get_db_connection(db_url)
    cursor = conn.cursor()
    
    # è·å–ä¸»é”®ä¿¡æ¯
    cursor.execute("""
        SELECT 
            tc.table_name,
            kcu.column_name,
            tc.constraint_type
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu 
            ON tc.constraint_name = kcu.constraint_name
        WHERE tc.table_schema = 'public'
          AND tc.constraint_type = 'PRIMARY KEY'
        ORDER BY tc.table_name, kcu.ordinal_position;
    """)
    
    primary_keys = {}
    for row in cursor.fetchall():
        table_name, column_name, constraint_type = row
        if table_name not in primary_keys:
            primary_keys[table_name] = []
        primary_keys[table_name].append(column_name)
    
    # è·å–å¤–é”®ä¿¡æ¯
    cursor.execute("""
        SELECT 
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu 
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage ccu 
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.table_schema = 'public'
          AND tc.constraint_type = 'FOREIGN KEY';
    """)
    
    foreign_keys = {}
    for row in cursor.fetchall():
        table_name, column_name, foreign_table, foreign_column = row
        if table_name not in foreign_keys:
            foreign_keys[table_name] = []
        foreign_keys[table_name].append({
            'column': column_name,
            'foreign_table': foreign_table,
            'foreign_column': foreign_column
        })
    
    cursor.close()
    conn.close()
    
    return primary_keys, foreign_keys

def analyze_database_differences():
    """åˆ†ææœ¬åœ°å’ŒOVSæ•°æ®åº“çš„å·®å¼‚"""
    print("=== åˆ†ææ•°æ®åº“ç»“æ„å·®å¼‚ ===")
    
    # è·å–æœ¬åœ°æ•°æ®åº“ç»“æ„
    print("æ­£åœ¨è·å–æœ¬åœ°æ•°æ®åº“ç»“æ„...")
    local_tables = get_table_columns(LOCAL_DB_URL)
    local_pk, local_fk = get_table_constraints(LOCAL_DB_URL)
    print(f"âœ… æœ¬åœ°æ•°æ®åº“: {len(local_tables)} ä¸ªè¡¨")
    
    # è·å–OVSæ•°æ®åº“ç»“æ„
    print("æ­£åœ¨è·å–pma_db_ovsæ•°æ®åº“ç»“æ„...")
    try:
        ovs_tables = get_table_columns(OVS_DB_URL)
        ovs_pk, ovs_fk = get_table_constraints(OVS_DB_URL)
        print(f"âœ… pma_db_ovsæ•°æ®åº“: {len(ovs_tables)} ä¸ªè¡¨")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥pma_db_ovsæ•°æ®åº“: {str(e)}")
        return None
    
    # åˆ†æå·®å¼‚
    differences = {
        'missing_tables': [],      # OVSç¼ºå¤±çš„è¡¨
        'extra_tables': [],        # OVSå¤šå‡ºçš„è¡¨
        'table_differences': {}    # è¡¨ç»“æ„å·®å¼‚
    }
    
    local_table_names = set(local_tables.keys())
    ovs_table_names = set(ovs_tables.keys())
    
    # æ‰¾å‡ºç¼ºå¤±å’Œå¤šä½™çš„è¡¨
    differences['missing_tables'] = list(local_table_names - ovs_table_names)
    differences['extra_tables'] = list(ovs_table_names - local_table_names)
    
    print(f"\nğŸ“Š å·®å¼‚åˆ†æç»“æœ:")
    print(f"  - OVSç¼ºå¤±è¡¨: {len(differences['missing_tables'])} ä¸ª")
    print(f"  - OVSå¤šä½™è¡¨: {len(differences['extra_tables'])} ä¸ª")
    
    if differences['missing_tables']:
        print(f"  ç¼ºå¤±çš„è¡¨: {', '.join(differences['missing_tables'])}")
    
    # å¯¹æ¯”å…±åŒè¡¨çš„åˆ—å·®å¼‚
    common_tables = local_table_names & ovs_table_names
    for table_name in common_tables:
        local_columns = {col['column_name']: col for col in local_tables[table_name]}
        ovs_columns = {col['column_name']: col for col in ovs_tables[table_name]}
        
        table_diff = {
            'missing_columns': [],
            'extra_columns': [],
            'column_differences': []
        }
        
        # æ‰¾å‡ºç¼ºå¤±å’Œå¤šä½™çš„åˆ—
        local_col_names = set(local_columns.keys())
        ovs_col_names = set(ovs_columns.keys())
        
        table_diff['missing_columns'] = list(local_col_names - ovs_col_names)
        table_diff['extra_columns'] = list(ovs_col_names - local_col_names)
        
        # å¯¹æ¯”ç›¸åŒåˆ—çš„å±æ€§å·®å¼‚
        common_columns = local_col_names & ovs_col_names
        for col_name in common_columns:
            local_col = local_columns[col_name]
            ovs_col = ovs_columns[col_name]
            
            # æ¯”è¾ƒå…³é”®å±æ€§
            if (local_col['data_type'] != ovs_col['data_type'] or
                local_col['is_nullable'] != ovs_col['is_nullable'] or
                local_col['character_maximum_length'] != ovs_col['character_maximum_length']):
                table_diff['column_differences'].append({
                    'column': col_name,
                    'local': local_col,
                    'ovs': ovs_col
                })
        
        # åªæœ‰å­˜åœ¨å·®å¼‚æ—¶æ‰è®°å½•
        if (table_diff['missing_columns'] or 
            table_diff['extra_columns'] or 
            table_diff['column_differences']):
            differences['table_differences'][table_name] = table_diff
    
    if differences['table_differences']:
        print(f"  - è¡¨ç»“æ„å·®å¼‚: {len(differences['table_differences'])} ä¸ªè¡¨")
    
    return differences, local_tables, local_pk, local_fk

def generate_create_table_sql(table_name, columns, primary_keys):
    """ç”Ÿæˆåˆ›å»ºè¡¨çš„SQL"""
    col_definitions = []
    
    for col in columns:
        col_name = col['column_name']
        data_type = col['data_type']
        
        # å¤„ç†æ•°æ®ç±»å‹
        if col['character_maximum_length']:
            data_type += f"({col['character_maximum_length']})"
        elif col['numeric_precision'] and col['numeric_scale'] is not None:
            data_type += f"({col['numeric_precision']},{col['numeric_scale']})"
        elif col['numeric_precision']:
            data_type += f"({col['numeric_precision']})"
        
        # å¤„ç†å¯ç©ºæ€§
        nullable = "" if col['is_nullable'] == 'YES' else " NOT NULL"
        
        # å¤„ç†é»˜è®¤å€¼
        default = ""
        if col['column_default']:
            default = f" DEFAULT {col['column_default']}"
        
        col_definitions.append(f"  {col_name} {data_type}{nullable}{default}")
    
    # æ·»åŠ ä¸»é”®
    if table_name in primary_keys and primary_keys[table_name]:
        pk_cols = ', '.join(primary_keys[table_name])
        col_definitions.append(f"  PRIMARY KEY ({pk_cols})")
    
    return f"CREATE TABLE {table_name} (\n" + ",\n".join(col_definitions) + "\n);"

def generate_sync_sql(differences, local_tables, local_pk, local_fk):
    """ç”ŸæˆåŒæ­¥SQLè¯­å¥"""
    print("\n=== ç”ŸæˆåŒæ­¥SQL ===")
    
    sql_statements = []
    
    # 1. åˆ›å»ºç¼ºå¤±çš„è¡¨
    for table_name in differences['missing_tables']:
        print(f"  ç”Ÿæˆåˆ›å»ºè¡¨SQL: {table_name}")
        columns = local_tables[table_name]
        create_sql = generate_create_table_sql(table_name, columns, local_pk)
        sql_statements.append(create_sql)
    
    # 2. æ·»åŠ ç¼ºå¤±çš„åˆ—
    for table_name, table_diff in differences['table_differences'].items():
        for col_name in table_diff['missing_columns']:
            print(f"  ç”Ÿæˆæ·»åŠ åˆ—SQL: {table_name}.{col_name}")
            # ä»æœ¬åœ°ç»“æ„ä¸­æ‰¾åˆ°åˆ—å®šä¹‰
            local_columns = {col['column_name']: col for col in local_tables[table_name]}
            col_info = local_columns[col_name]
            
            data_type = col_info['data_type']
            if col_info['character_maximum_length']:
                data_type += f"({col_info['character_maximum_length']})"
            elif col_info['numeric_precision'] and col_info['numeric_scale'] is not None:
                data_type += f"({col_info['numeric_precision']},{col_info['numeric_scale']})"
            elif col_info['numeric_precision']:
                data_type += f"({col_info['numeric_precision']})"
            
            nullable = "" if col_info['is_nullable'] == 'YES' else " NOT NULL"
            default = f" DEFAULT {col_info['column_default']}" if col_info['column_default'] else ""
            
            alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {col_name} {data_type}{nullable}{default};"
            sql_statements.append(alter_sql)
    
    return sql_statements

def execute_sync_sql(sql_statements):
    """æ‰§è¡ŒåŒæ­¥SQL"""
    if not sql_statements:
        print("âœ… æ— éœ€æ‰§è¡ŒåŒæ­¥SQL")
        return True
    
    print(f"\n=== å‡†å¤‡æ‰§è¡Œ {len(sql_statements)} æ¡åŒæ­¥SQL ===")
    
    # æ˜¾ç¤ºSQLé¢„è§ˆ
    print("\nå°†è¦æ‰§è¡Œçš„SQLè¯­å¥:")
    for i, sql in enumerate(sql_statements, 1):
        # åªæ˜¾ç¤ºå‰å‡ è¡Œï¼Œé¿å…è¾“å‡ºè¿‡é•¿
        if i <= 10:
            print(f"{i:2d}. {sql[:100]}{'...' if len(sql) > 100 else ''}")
        elif i == 11:
            print(f"    ... è¿˜æœ‰ {len(sql_statements) - 10} æ¡SQLè¯­å¥")
    
    # ç¡®è®¤æ‰§è¡Œ
    print(f"\nâš ï¸ æ³¨æ„ï¼šè¿™äº›æ“ä½œå°†ä¿®æ”¹pma_db_ovsæ•°æ®åº“ç»“æ„")
    print("è¿™ä¼šæ·»åŠ ç¼ºå¤±çš„è¡¨å’Œåˆ—ï¼Œä¸ä¼šåˆ é™¤ç°æœ‰æ•°æ®")
    
    confirm = input(f"\næ˜¯å¦æ‰§è¡Œä»¥ä¸Š {len(sql_statements)} æ¡SQLè¯­å¥ï¼Ÿ(y/N): ")
    if confirm.lower() != 'y':
        print("âŒ ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ")
        return False
    
    try:
        print("\næ­£åœ¨è¿æ¥pma_db_ovsæ•°æ®åº“...")
        conn = get_db_connection(OVS_DB_URL)
        cursor = conn.cursor()
        
        print("å¼€å§‹æ‰§è¡ŒåŒæ­¥SQL...")
        success_count = 0
        
        for i, sql in enumerate(sql_statements, 1):
            try:
                print(f"æ‰§è¡Œç¬¬ {i:2d} æ¡SQL: ", end="", flush=True)
                cursor.execute(sql)
                conn.commit()
                print("âœ… æˆåŠŸ")
                success_count += 1
            except Exception as e:
                print(f"âŒ å¤±è´¥: {str(e)}")
                conn.rollback()
                # ç»§ç»­æ‰§è¡Œå…¶ä»–SQL
        
        cursor.close()
        conn.close()
        
        print(f"\nğŸ“Š æ‰§è¡Œç»“æœ: {success_count}/{len(sql_statements)} æ¡SQLæˆåŠŸæ‰§è¡Œ")
        
        if success_count == len(sql_statements):
            print("ğŸ‰ æ‰€æœ‰åŒæ­¥SQLæ‰§è¡ŒæˆåŠŸï¼")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†åŒæ­¥SQLæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return False
        
    except Exception as e:
        print(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=== æœ¬åœ°æ•°æ®åº“ç»“æ„åŒæ­¥åˆ°pma_db_ovs ===")
    print(f"æºæ•°æ®åº“: {LOCAL_DB_URL}")
    print(f"ç›®æ ‡æ•°æ®åº“: {OVS_DB_URL.replace(OVS_DB_URL.split('@')[0].split(':')[-1], '***')}")
    print()
    
    try:
        # 1. å¤‡ä»½OVSæ•°æ®åº“
        backup_file = backup_ovs_database()
        if not backup_file:
            print("âŒ å¤‡ä»½å¤±è´¥ï¼Œå»ºè®®ä¿®å¤å¤‡ä»½é—®é¢˜åå†åŒæ­¥")
            confirm = input("æ˜¯å¦è·³è¿‡å¤‡ä»½ç»§ç»­åŒæ­¥ï¼Ÿ(y/N): ")
            if confirm.lower() != 'y':
                return
        print()
        
        # 2. åˆ†ææ•°æ®åº“å·®å¼‚
        analysis_result = analyze_database_differences()
        if analysis_result is None:
            return
        
        differences, local_tables, local_pk, local_fk = analysis_result
        
        # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
        total_changes = (len(differences['missing_tables']) + 
                        sum(len(td['missing_columns']) for td in differences['table_differences'].values()))
        
        if total_changes == 0:
            print("\nâœ… pma_db_ovsæ•°æ®åº“ç»“æ„å·²ç»æ˜¯æœ€æ–°çš„ï¼Œæ— éœ€åŒæ­¥")
            return
        
        print(f"\nğŸ“‹ éœ€è¦åŒæ­¥ {total_changes} é¡¹æ›´æ”¹")
        
        # 4. ç”ŸæˆåŒæ­¥SQL
        sql_statements = generate_sync_sql(differences, local_tables, local_pk, local_fk)
        
        # 5. ä¿å­˜SQLåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sql_file = f"pma_db_ovs_sync_{timestamp}.sql"
        
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write("-- pma_db_ovsæ•°æ®åº“ç»“æ„åŒæ­¥SQL\n")
            f.write(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"-- æºæ•°æ®åº“: {LOCAL_DB_URL}\n")
            f.write(f"-- ç›®æ ‡æ•°æ®åº“: pma_db_ovs\n\n")
            
            for sql in sql_statements:
                f.write(sql + "\n\n")
        
        print(f"\nğŸ“„ åŒæ­¥SQLå·²ä¿å­˜åˆ°: {sql_file}")
        
        # 6. æ‰§è¡ŒåŒæ­¥
        success = execute_sync_sql(sql_statements)
        
        if success:
            print(f"\nğŸ‰ æ•°æ®åº“ç»“æ„åŒæ­¥å®Œæˆï¼")
            if backup_file:
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
            print(f"ğŸ“„ åŒæ­¥SQL: {sql_file}")
        else:
            print(f"\nâš ï¸ æ•°æ®åº“åŒæ­¥æœªå®Œå…¨æˆåŠŸ")
            if backup_file:
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
            print(f"ğŸ“„ åŒæ­¥SQL: {sql_file}")
    
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main() 