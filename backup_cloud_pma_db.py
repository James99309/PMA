#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PMAäº‘ç«¯æ•°æ®åº“å¤‡ä»½å’Œæœ¬åœ°ç»“æ„åŒæ­¥è„šæœ¬
åŠŸèƒ½ï¼š
1. å¤‡ä»½äº‘ç«¯PostgreSQLæ•°æ®åº“ pma_db_sp8d
2. è·å–æœ¬åœ°æ•°æ®åº“ç»“æ„
3. å°†æœ¬åœ°ç»“æ„åŒæ­¥åˆ°äº‘ç«¯æ•°æ®åº“ï¼ˆä¸ç ´åæ•°æ®ï¼‰
4. éªŒè¯æ•°æ®å®Œæ•´æ€§
"""

import os
import sys
import psycopg2
import logging
import subprocess
import datetime
from urllib.parse import urlparse
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('PMAäº‘ç«¯æ•°æ®åº“åŒæ­¥')

class PMACloudDBSync:
    def __init__(self):
        self.timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        self.backup_dir = os.path.join(os.getcwd(), 'cloud_db_backups')
        os.makedirs(self.backup_dir, exist_ok=True)
        
        # äº‘ç«¯æ•°æ®åº“è¿æ¥ä¿¡æ¯
        self.cloud_db_url = "postgresql://pma_db_sp8d_user:LXNGJmR6bFrNecoaWbdbdzPpltIAd40w@dpg-d0b1gl1r0fns73d1jc1g-a.singapore-postgres.render.com/pma_db_sp8d"
        
        # æœ¬åœ°æ•°æ®åº“URLï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤é…ç½®è·å–ï¼‰
        self.local_db_url = os.environ.get('DATABASE_URL')
        if not self.local_db_url:
            # å°è¯•ä»config.pyè·å–
            try:
                import config
                self.local_db_url = config.Config.SQLALCHEMY_DATABASE_URI
            except:
                self.local_db_url = "sqlite:///app.db"  # é»˜è®¤SQLite
        
        logger.info(f"äº‘ç«¯æ•°æ®åº“: {self.cloud_db_url.split('@')[1] if '@' in self.cloud_db_url else 'Hidden'}")
        logger.info(f"æœ¬åœ°æ•°æ®åº“: {self.local_db_url.split('@')[1] if '@' in self.local_db_url else self.local_db_url}")

    def parse_db_url(self, db_url):
        """è§£ææ•°æ®åº“URL"""
        if db_url.startswith('sqlite'):
            return {'type': 'sqlite', 'path': db_url.replace('sqlite:///', '')}
        
        parsed = urlparse(db_url)
        return {
            'type': 'postgresql',
            'host': parsed.hostname,
            'port': parsed.port or 5432,
            'user': parsed.username,
            'password': parsed.password,
            'dbname': parsed.path.lstrip('/')
        }

    def test_cloud_connection(self):
        """æµ‹è¯•äº‘ç«¯æ•°æ®åº“è¿æ¥"""
        logger.info("æµ‹è¯•äº‘ç«¯æ•°æ®åº“è¿æ¥...")
        try:
            cloud_params = self.parse_db_url(self.cloud_db_url)
            conn = psycopg2.connect(
                host=cloud_params['host'],
                port=cloud_params['port'],
                user=cloud_params['user'],
                password=cloud_params['password'],
                dbname=cloud_params['dbname']
            )
            cursor = conn.cursor()
            cursor.execute("SELECT version();")
            version = cursor.fetchone()
            logger.info(f"äº‘ç«¯æ•°æ®åº“è¿æ¥æˆåŠŸ: {version[0][:60]}...")
            
            # è·å–æ•°æ®åº“å¤§å°å’Œè¡¨ç»Ÿè®¡
            cursor.execute("SELECT pg_size_pretty(pg_database_size(current_database()));")
            db_size = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(*) as table_count 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            """)
            table_count = cursor.fetchone()[0]
            
            logger.info(f"æ•°æ®åº“å¤§å°: {db_size}, è¡¨æ•°é‡: {table_count}")
            
            cursor.close()
            conn.close()
            return True
        except Exception as e:
            logger.error(f"äº‘ç«¯æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            return False

    def backup_cloud_database(self):
        """å¤‡ä»½äº‘ç«¯æ•°æ®åº“"""
        logger.info("å¼€å§‹å¤‡ä»½äº‘ç«¯æ•°æ®åº“...")
        
        cloud_params = self.parse_db_url(self.cloud_db_url)
        backup_file = os.path.join(self.backup_dir, f'pma_db_sp8d_backup_{self.timestamp}.sql')
        info_file = os.path.join(self.backup_dir, f'backup_info_{self.timestamp}.md')
        
        try:
            # ä½¿ç”¨pg_dumpå¤‡ä»½æ•°æ®åº“ (SQLæ ¼å¼)
            cmd_sql = [
                'pg_dump',
                '-h', cloud_params['host'],
                '-p', str(cloud_params['port']),
                '-U', cloud_params['user'],
                '-d', cloud_params['dbname'],
                '--verbose',
                '--clean',
                '--if-exists',
                '--no-owner',
                '--no-privileges',
                '-f', backup_file
            ]
            
            # è®¾ç½®å¯†ç ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['PGPASSWORD'] = cloud_params['password']
            
            logger.info("æ‰§è¡ŒSQLæ ¼å¼å¤‡ä»½...")
            result = subprocess.run(cmd_sql, env=env, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"SQLæ ¼å¼å¤‡ä»½æˆåŠŸ: {backup_file}")
                
                # ç”Ÿæˆå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
                backup_rows = self.generate_backup_info(cloud_params, backup_file, info_file)
                
                return backup_file
            else:
                logger.error(f"å¤‡ä»½å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            logger.error(f"å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return None

    def generate_backup_info(self, db_params, backup_file, info_file):
        """ç”Ÿæˆå¤‡ä»½ä¿¡æ¯æ–‡ä»¶"""
        try:
            conn = psycopg2.connect(
                host=db_params['host'],
                port=db_params['port'],
                user=db_params['user'],
                password=db_params['password'],
                dbname=db_params['dbname']
            )
            cursor = conn.cursor()
            
            # è·å–æ•°æ®åº“ä¿¡æ¯
            cursor.execute("SELECT version();")
            db_version = cursor.fetchone()[0]
            
            cursor.execute("SELECT pg_size_pretty(pg_database_size(current_database()));")
            db_size = cursor.fetchone()[0]
            
            # è·å–è¡¨è¡Œæ•°ç»Ÿè®¡
            cursor.execute("""
                SELECT table_name
                FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
                ORDER BY table_name;
            """)
            tables = cursor.fetchall()
            
            row_counts = []
            total_rows = 0
            for (table_name,) in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
                    count = cursor.fetchone()[0]
                    row_counts.append((table_name, count))
                    total_rows += count
                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–è¡¨ {table_name} çš„è¡Œæ•°: {e}")
                    row_counts.append((table_name, 0))
            
            # ç”Ÿæˆä¿¡æ¯æ–‡æ¡£
            info_content = f"""# PMAäº‘ç«¯æ•°æ®åº“å¤‡ä»½ä¿¡æ¯

## å¤‡ä»½åŸºæœ¬ä¿¡æ¯
- å¤‡ä»½æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- å¤‡ä»½æ–‡ä»¶: {os.path.basename(backup_file)}
- æ•°æ®åº“ä¸»æœº: {db_params['host']}
- æ•°æ®åº“åç§°: {db_params['dbname']}
- æ•°æ®åº“ç‰ˆæœ¬: {db_version}
- æ•°æ®åº“å¤§å°: {db_size}

## è¡¨æ•°æ®ç»Ÿè®¡
| è¡¨å | å½“å‰è¡Œæ•° |
|------|----------|
"""
            
            for table_name, row_count in row_counts:
                info_content += f"| {table_name} | {row_count} |\n"
            
            # æ·»åŠ æ€»è®¡
            info_content += f"| **æ€»è®¡** | **{total_rows}** |\n"
            
            with open(info_file, 'w', encoding='utf-8') as f:
                f.write(info_content)
            
            logger.info(f"å¤‡ä»½ä¿¡æ¯æ–‡ä»¶å·²ç”Ÿæˆ: {info_file}")
            logger.info(f"æ•°æ®åº“æ€»è¡Œæ•°: {total_rows}")
            
            cursor.close()
            conn.close()
            
            return total_rows
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤‡ä»½ä¿¡æ¯å¤±è´¥: {str(e)}")
            return 0

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„å¤‡ä»½æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹PMAäº‘ç«¯æ•°æ®åº“å¤‡ä»½æµç¨‹...")
        
        # 1. æµ‹è¯•äº‘ç«¯è¿æ¥
        if not self.test_cloud_connection():
            logger.error("âŒ äº‘ç«¯æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œå‡­æ®")
            return False
        
        # 2. å¤‡ä»½äº‘ç«¯æ•°æ®åº“
        backup_file = self.backup_cloud_database()
        if not backup_file:
            logger.error("âŒ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å¤±è´¥")
            return False
        
        # 3. éªŒè¯æ•°æ®å®Œæ•´æ€§
        verify_rows = self.verify_data_integrity()
        
        logger.info("ğŸ‰ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å®Œæˆ!")
        logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: {verify_rows} è¡Œ")
        logger.info(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
        
        return True

    def verify_data_integrity(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        logger.info("éªŒè¯äº‘ç«¯æ•°æ®åº“æ•°æ®å®Œæ•´æ€§...")
        
        try:
            cloud_params = self.parse_db_url(self.cloud_db_url)
            conn = psycopg2.connect(
                host=cloud_params['host'],
                port=cloud_params['port'],
                user=cloud_params['user'],
                password=cloud_params['password'],
                dbname=cloud_params['dbname']
            )
            cursor = conn.cursor()
            
            # è·å–è¡¨è¡Œæ•°ç»Ÿè®¡
            cursor.execute("""
                SELECT table_name
                FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
                ORDER BY table_name;
            """)
            tables = cursor.fetchall()
            
            total_rows = 0
            for (table_name,) in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
                    count = cursor.fetchone()[0]
                    total_rows += count
                    logger.info(f"  {table_name}: {count} è¡Œ")
                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–è¡¨ {table_name} çš„è¡Œæ•°: {e}")
            
            logger.info(f"æ€»æ•°æ®è¡Œæ•°: {total_rows}")
            
            cursor.close()
            conn.close()
            
            return total_rows
            
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {str(e)}")
            return 0

if __name__ == "__main__":
    sync_tool = PMACloudDBSync()
    success = sync_tool.run()
    if success:
        logger.info("ğŸ¯ å¤‡ä»½æ“ä½œæˆåŠŸå®Œæˆ!")
    else:
        logger.error("ğŸ’¥ å¤‡ä»½æ“ä½œå¤±è´¥!")
