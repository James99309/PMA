#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæ­¥æœ¬åœ°æ•°æ®åº“ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“
1. å¤‡ä»½äº‘ç«¯æ•°æ®åº“å†…å®¹
2. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„
3. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ï¼ˆä¸åŒ…å«æ•°æ®ï¼‰
"""

import os
import sys
import psycopg2
import subprocess
import logging
from datetime import datetime
from urllib.parse import urlparse
import tempfile

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
LOCAL_DB_URL = "postgresql://nijie@localhost:5432/pma_local"
CLOUD_DB_URL = "postgresql://pma_db_ovs_user:oUKdxwqXDvCrgkg3fkZ33axXgDF21D51@dpg-d170laodl3ps739trgp0-a.singapore-postgres.render.com/pma_db_ovs"

def parse_database_url(db_url):
    """è§£ææ•°æ®åº“URL"""
    parsed = urlparse(db_url)
    return {
        'host': parsed.hostname,
        'port': parsed.port or 5432,
        'username': parsed.username,
        'password': parsed.password,
        'database': parsed.path.lstrip('/')
    }

def test_database_connection(db_url, db_name):
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        version = cursor.fetchone()[0]
        cursor.close()
        conn.close()
        logger.info(f"âœ… {db_name}æ•°æ®åº“è¿æ¥æˆåŠŸ")
        logger.info(f"   ç‰ˆæœ¬: {version[:50]}...")
        return True
    except Exception as e:
        logger.error(f"âŒ {db_name}æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

def backup_cloud_database():
    """å¤‡ä»½äº‘ç«¯æ•°æ®åº“"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_filename = f"cloud_backup_pma_db_ovs_{timestamp}.sql"
    backup_path = os.path.join('backups', backup_filename)
    
    # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
    os.makedirs('backups', exist_ok=True)
    
    try:
        logger.info("ğŸ”„ å¼€å§‹å¤‡ä»½äº‘ç«¯æ•°æ®åº“...")
        
        cloud_config = parse_database_url(CLOUD_DB_URL)
        
        # æ„å»ºpg_dumpå‘½ä»¤
        cmd = [
            'pg_dump',
            '--host', cloud_config['host'],
            '--port', str(cloud_config['port']),
            '--username', cloud_config['username'],
            '--no-password',
            '--format', 'plain',
            '--clean',
            '--create',
            '--encoding', 'UTF8',
            '--verbose',
            cloud_config['database']
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['PGPASSWORD'] = cloud_config['password']
        
        # æ‰§è¡Œå¤‡ä»½å‘½ä»¤
        with open(backup_path, 'w') as f:
            result = subprocess.run(
                cmd,
                stdout=f,
                stderr=subprocess.PIPE,
                env=env,
                text=True
            )
        
        if result.returncode == 0:
            file_size = os.path.getsize(backup_path) / (1024 * 1024)  # MB
            logger.info(f"âœ… äº‘ç«¯æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_filename}")
            logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            logger.info(f"   å¤‡ä»½è·¯å¾„: {backup_path}")
            return backup_path
        else:
            logger.error(f"âŒ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å¤±è´¥: {result.stderr}")
            if os.path.exists(backup_path):
                os.remove(backup_path)
            return None
            
    except Exception as e:
        logger.error(f"âŒ å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if os.path.exists(backup_path):
            os.remove(backup_path)
        return None

def export_local_schema():
    """å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    schema_filename = f"local_schema_{timestamp}.sql"
    schema_path = os.path.join('backups', schema_filename)
    
    try:
        logger.info("ğŸ”„ å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„...")
        
        local_config = parse_database_url(LOCAL_DB_URL)
        
        # æ„å»ºpg_dumpå‘½ä»¤ï¼ˆåªå¯¼å‡ºç»“æ„ï¼‰
        cmd = [
            'pg_dump',
            '--host', local_config['host'],
            '--port', str(local_config['port']),
            '--username', local_config['username'],
            '--no-password',
            '--format', 'plain',
            '--schema-only',  # åªå¯¼å‡ºç»“æ„
            '--clean',
            '--no-owner',
            '--no-privileges',
            '--encoding', 'UTF8',
            '--verbose',
            local_config['database']
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        if local_config['password']:
            env['PGPASSWORD'] = local_config['password']
        
        # æ‰§è¡Œå¯¼å‡ºå‘½ä»¤
        with open(schema_path, 'w') as f:
            result = subprocess.run(
                cmd,
                stdout=f,
                stderr=subprocess.PIPE,
                env=env,
                text=True
            )
        
        if result.returncode == 0:
            file_size = os.path.getsize(schema_path) / 1024  # KB
            logger.info(f"âœ… æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºæˆåŠŸ: {schema_filename}")
            logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
            logger.info(f"   å¯¼å‡ºè·¯å¾„: {schema_path}")
            return schema_path
        else:
            logger.error(f"âŒ æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥: {result.stderr}")
            if os.path.exists(schema_path):
                os.remove(schema_path)
            return None
            
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if os.path.exists(schema_path):
            os.remove(schema_path)
        return None

def sync_schema_to_cloud(schema_path):
    """åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“"""
    try:
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“...")
        
        cloud_config = parse_database_url(CLOUD_DB_URL)
        
        # æ„å»ºpsqlå‘½ä»¤
        cmd = [
            'psql',
            '--host', cloud_config['host'],
            '--port', str(cloud_config['port']),
            '--username', cloud_config['username'],
            '--dbname', cloud_config['database'],
            '--no-password',
            '--file', schema_path,
            '--echo-errors',
            '--set', 'ON_ERROR_STOP=1'
        ]
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['PGPASSWORD'] = cloud_config['password']
        
        # æ‰§è¡ŒåŒæ­¥å‘½ä»¤
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env=env,
            text=True
        )
        
        if result.returncode == 0:
            logger.info("âœ… æ•°æ®åº“ç»“æ„åŒæ­¥æˆåŠŸ")
            logger.info("   æ‰€æœ‰è¡¨ç»“æ„å·²æ›´æ–°åˆ°äº‘ç«¯æ•°æ®åº“")
            return True
        else:
            logger.error(f"âŒ æ•°æ®åº“ç»“æ„åŒæ­¥å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def verify_sync_result():
    """éªŒè¯åŒæ­¥ç»“æœ"""
    try:
        logger.info("ğŸ”„ éªŒè¯åŒæ­¥ç»“æœ...")
        
        # è¿æ¥äº‘ç«¯æ•°æ®åº“
        cloud_conn = psycopg2.connect(CLOUD_DB_URL)
        cloud_cursor = cloud_conn.cursor()
        
        # è·å–è¡¨æ•°é‡
        cloud_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = 'public'
        """)
        cloud_table_count = cloud_cursor.fetchone()[0]
        
        # è·å–åºåˆ—æ•°é‡
        cloud_cursor.execute("""
            SELECT COUNT(*) FROM information_schema.sequences 
            WHERE sequence_schema = 'public'
        """)
        cloud_sequence_count = cloud_cursor.fetchone()[0]
        
        # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
        key_tables = ['users', 'projects', 'quotations', 'products', 'companies']
        existing_tables = []
        
        for table in key_tables:
            cloud_cursor.execute("""
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = %s
            """, (table,))
            if cloud_cursor.fetchone()[0] > 0:
                existing_tables.append(table)
        
        cloud_cursor.close()
        cloud_conn.close()
        
        logger.info("ğŸ“Š åŒæ­¥ç»“æœéªŒè¯:")
        logger.info(f"   - äº‘ç«¯è¡¨æ•°é‡: {cloud_table_count}")
        logger.info(f"   - äº‘ç«¯åºåˆ—æ•°é‡: {cloud_sequence_count}")
        logger.info(f"   - å…³é”®è¡¨å­˜åœ¨: {len(existing_tables)}/{len(key_tables)}")
        logger.info(f"   - å­˜åœ¨çš„å…³é”®è¡¨: {', '.join(existing_tables)}")
        
        if len(existing_tables) == len(key_tables):
            logger.info("âœ… åŒæ­¥éªŒè¯æˆåŠŸ - æ‰€æœ‰å…³é”®è¡¨éƒ½å­˜åœ¨")
            return True
        else:
            missing_tables = set(key_tables) - set(existing_tables)
            logger.warning(f"âš ï¸ éƒ¨åˆ†å…³é”®è¡¨ç¼ºå¤±: {', '.join(missing_tables)}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ åŒæ­¥æœ¬åœ°æ•°æ®åº“ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“")
    print("=" * 80)
    print("ğŸ“‹ ä»»åŠ¡è¯´æ˜:")
    print("   1. å¤‡ä»½äº‘ç«¯æ•°æ®åº“å†…å®¹")
    print("   2. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„")
    print("   3. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“ï¼ˆä¸åŒ…å«æ•°æ®ï¼‰")
    print("=" * 80)
    
    # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
    print("\nğŸ“‹ æ­¥éª¤1: æµ‹è¯•æ•°æ®åº“è¿æ¥")
    if not test_database_connection(LOCAL_DB_URL, "æœ¬åœ°"):
        print("âŒ æœ¬åœ°æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    if not test_database_connection(CLOUD_DB_URL, "äº‘ç«¯"):
        print("âŒ äº‘ç«¯æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 2. å¤‡ä»½äº‘ç«¯æ•°æ®åº“
    print("\nğŸ“‹ æ­¥éª¤2: å¤‡ä»½äº‘ç«¯æ•°æ®åº“")
    backup_path = backup_cloud_database()
    if not backup_path:
        print("âŒ äº‘ç«¯æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 3. å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„
    print("\nğŸ“‹ æ­¥éª¤3: å¯¼å‡ºæœ¬åœ°æ•°æ®åº“ç»“æ„")
    schema_path = export_local_schema()
    if not schema_path:
        print("âŒ æœ¬åœ°æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # 4. ç¡®è®¤åŒæ­¥æ“ä½œ
    print("\nğŸ“‹ æ­¥éª¤4: ç¡®è®¤åŒæ­¥æ“ä½œ")
    print("âš ï¸ è­¦å‘Šï¼šå³å°†è¦†ç›–äº‘ç«¯æ•°æ®åº“ç»“æ„ï¼")
    print(f"   - äº‘ç«¯æ•°æ®åº“: pma_db_ovs")
    print(f"   - å¤‡ä»½æ–‡ä»¶: {backup_path}")
    print(f"   - ç»“æ„æ–‡ä»¶: {schema_path}")
    
    confirm = input("\næ˜¯å¦ç»§ç»­åŒæ­¥ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ")
    if confirm != 'YES':
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return False
    
    # 5. åŒæ­¥ç»“æ„åˆ°äº‘ç«¯
    print("\nğŸ“‹ æ­¥éª¤5: åŒæ­¥ç»“æ„åˆ°äº‘ç«¯æ•°æ®åº“")
    if not sync_schema_to_cloud(schema_path):
        print("âŒ æ•°æ®åº“ç»“æ„åŒæ­¥å¤±è´¥")
        return False
    
    # 6. éªŒè¯åŒæ­¥ç»“æœ
    print("\nğŸ“‹ æ­¥éª¤6: éªŒè¯åŒæ­¥ç»“æœ")
    if not verify_sync_result():
        print("âš ï¸ åŒæ­¥éªŒè¯æœ‰è­¦å‘Šï¼Œè¯·æ£€æŸ¥")
    
    print("\nğŸ‰ æ•°æ®åº“ç»“æ„åŒæ­¥å®Œæˆï¼")
    print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {backup_path}")
    print(f"ğŸ“ ç»“æ„æ–‡ä»¶ä¿å­˜åœ¨: {schema_path}")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        if success:
            print("\nâœ… ä»»åŠ¡å®Œæˆ")
            sys.exit(0)
        else:
            print("\nâŒ ä»»åŠ¡å¤±è´¥")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 